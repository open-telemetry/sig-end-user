# OTel Me...with Oluwatomisin Taiwo and Andrei Morozov

Published on 2025-06-11T05:54:28Z

## Description

oin us for the next edition of OTel Me. This time, we'll hear from Oluwatomisin Taiwo and Andrei Morozov of Compass Digital as ...

URL: https://www.youtube.com/watch?v=tTCuTAPE5aQ

## Summary

In this episode of Hotel Me, hosts Adriana Vila and Andre Kapolski discuss observability practices at Compass Digital with guests Tommy and Andre M. from the S3 team. They delve into the roles of observability in ensuring system reliability and scalability, touching on the use of AWS services like Lambda and ECS, and the integration of OpenTelemetry for distributed tracing and performance monitoring. Key challenges addressed include context propagation in microservices, manual instrumentation for business logic, and the need for effective log management. The conversation highlights the importance of community support, with participants sharing their experiences and encouraging more complex examples in OpenTelemetry resources. They also discuss future expectations for OpenTelemetry, emphasizing the potential for enhanced data insights and improved developer experiences. The session concludes with an invitation for audience engagement and a reminder of upcoming community events.

## Chapters

Sure! Here are the key moments from the livestream along with their timestamps:

00:00:00 Introductions by Adriana Vila and Andre Kapolski  
00:02:00 Guests Introduce Themselves: Tommy and Andre M  
00:04:30 Discussion on Roles at Compass Digital  
00:06:15 Overview of System Architecture and Technologies Used  
00:10:00 Challenges Faced in Achieving Observability  
00:13:45 Insights on System Instrumentation Techniques  
00:18:30 Discussion on OpenTelemetry Setup and Configuration  
00:25:00 Audience Questions on Metrics and Logging  
00:30:00 Collecting and Managing Observability Data  
00:35:00 Future of OpenTelemetry in Their Workflow  
00:40:00 Closing Remarks and Upcoming Events  

Feel free to ask if you need further details!

# Hotel Me Session Transcript

**Adriana:** Heat. Heat. Hello everyone and welcome to our latest Hotel Me. I'm super excited for those who are able to join, and for those who are not, we do have this recording available after the fact, both on LinkedIn and YouTube. My name is Adriana Vila, and I am one of the maintainers of the Hotel End User SIG. I am happy to introduce my co-presenter today, Andre.

**Andre:** Hi everyone! Yeah, awesome to be here. My name is Andre Kapolski, and I'm a fairly recent contributor to the End User SIG. I'm super excited to hear more from our guests today.

**Adriana:** I think this is a perfect segue as we bring on our guests. Folks in the chat, please feel free to say where you're watching from.

**Andre:** I can start. I'm joining from the Czech Republic, specifically from Brno.

**Adriana:** Oh, that’s right! I'm in Toronto, Canada, so it's I guess 1:00 PM for me and evening for you, right? 

**Andre:** That's correct!

**Adriana:** Awesome! All right, let's bring our guests on. Hello everyone!

**Tommy:** Hello!

**Andre M:** Hey.

**Adriana:** Why don't you both introduce yourselves? Let's start with Tommy.

**Tommy:** My name is Tommy. I'm an SRE here at Compass Digital, and my primary responsibility is ensuring the reliability, scalability, and observability of our web platform. I work closely with the engineering team, product teams, and test engineers to ensure that our systems are robust and we have actionable insights into what's going on within our services. I'm calling from Cambridge, Ontario, Canada.

**Adriana:** Awesome! We're practically neighbors, just a few hours away from each other.

**Andre M:** Hi, I'm Andre M, from Bonneville, Durham region, also in Ontario. I've been in this industry for 11 years, always interested in tech since I was a kid. I work with Tommy on the same SRE team at Compass Digital and have similar responsibilities focused on observability and on-call incidents for our systems.

**Adriana:** Well, we're super excited to have you both on! Just a reminder for folks watching: if you have questions along the way, please feel free to post them in the chat. We will also take questions at the end.

**Andre:** Let's get started! You both talked a little bit about your roles; could you talk a bit more about your respective roles at Compass Digital in more detail?

**Tommy:** Sure! Most of my role is focused on ensuring the reliability and scalability of our systems. Recently, I've been working on one of our products, which is E-Club. I'm helping to get observability into what they're doing there. I work with AWS SDK, CDK, Terraform, and PagerDuty. I also help with observability backend data tracing, where we send all our OpenTelemetry data.

**Andre M:** When I started with Compass about five years ago, I began as a senior software engineer. My background is primarily in software engineering, but I've developed an interest in ops and infrastructure. My focus is on developer experience and platform engineering. Recently, I've been working on understanding systems and promoting observability, especially given our microservices architecture.

**Adriana:** Folks, can you tell us a bit more about the system you are operating? What is its architecture and what programming languages are used?

**Tommy:** We have two products, but I’ll focus on E-Club. Our main infrastructure is about 95% Lambda functions. We have over 300 Lambdas in our ecosystem, utilizing a hybrid of DynamoDB and Aurora RDS, and we're starting to use Fargate services. 

**Andre M:** On the E-Club side, we have a blend of Python and Django on the backend and JavaScript/TypeScript on the frontend. Everything runs on AWS ECS, which gives us flexibility and consistency across environments. Our CI/CD pipelines automate the process of building Docker images and deploying them onto ECS.

**Adriana:** Thank you! As a follow-up, what were the top three problems that compelled you to implement observability?

**Tommy:** Observability in a distributed system is never fully solved. One major challenge was distributed tracing. A single user request can touch many services, and without distributed tracing, reconstructing the journey of a request is nearly impossible, especially during issues. Another challenge was performance monitoring. For instance, we needed to know not just if a task succeeded, but how long it took and what resources were consumed. Finally, error tracking was crucial for us to correlate errors with logs and traces.

**Andre M:** For our end, context propagation was a primary concern due to our microservices and distributed nature. Additionally, we needed to provide developers with the ability to create their own alerts via Terraform instead of relying on a single team.

**Adriana:** Can you elaborate on the instrumentation of your systems and what types of instrumentation you are using?

**Tommy:** We use an agent for instrumentation on the E-Club side. It works well with our infrastructure, especially with Lambdas using Lambda layers. For ECS, we utilize AWS FireLens for log management, redirecting logs to a sidecar that handles exporting.

**Andre M:** Our platform uses a vendor agent that integrates seamlessly with our Lambda functions. We manage our ECS Fargate tasks using Terraform, which allows us to customize configurations and manage the collectors effectively.

**Adriana:** Who is responsible for instrumentation in your teams?

**Tommy:** We're trying to build a pre-packaged solution for developers to leverage for their own instrumentation. For now, most of the initial instrumentation was done manually for critical code paths.

**Andre M:** We’re evolving our processes and looking to provide more out-of-the-box solutions. The goal is to empower developers to manage their own instrumentation.

**Adriana:** Do you have any current challenges with OpenTelemetry that you think could be improved?

**Tommy:** One major challenge was the initial setup and ensuring context propagation across services. The API can be overwhelming, and more complex examples would help us navigate this better.

**Andre M:** I've mostly been learning through experience, and I agree that more real-world examples would be beneficial.

**Adriana:** How do you see OpenTelemetry evolving in your workflow over the next year?

**Tommy:** I believe the real value lies in the data we extract. We want to apply user journeys and business events to gain insights. 

**Andre M:** I see OpenTelemetry helping us mature our observability processes further, especially around logs and complex setups. More out-of-the-box integrations would simplify our configurations.

**Adriana:** Thank you both for sharing your insights today! Before we wrap up, do you have any final thoughts or shoutouts?

**Tommy:** Just a big thank you for having us!

**Andre M:** Same here! It's great to share our experiences.

**Adriana:** Thank you to everyone who attended! The recording will be available on LinkedIn and YouTube. Be sure to check out the Hotel End User SIG group on CNCF Slack to share your stories and join us for our meetings every two weeks. Thanks again, and see you next time!

## Raw YouTube Transcript

Heat. Heat. Hello everyone and welcome to our latest hotel me. super excited for the those who are able to join and for those who are not we do have the uh this recording available after the fact both on LinkedIn and YouTube. My name is Adriana Vila and I am one of the maintainers of the hotel enduser SIG and I am happy to introduce my uh co- uh presenter today Andre. Hi everyone and yeah awesome to be here. My name is Andre Kapolski and I'm a fairly recent uh contributor to and end user sik. So yeah, I'm super excited to hear more from our our guests today. Yeah, and I think uh this is a perfect segue as we bring on our guests. And as we do um folks on the chat, please feel free to uh say where you're uh where you're watching from. Yeah. I can perhaps start. I'm watching from or I'm joining from the Czech Republic uh and in in EU uh and specifically in Berno. Adriana, what about you? Where I I don't think you mentioned it, have you? Oh, yeah. That's right. I'm in Toronto, Canada, so it's I guess 1:00 for me and I guess it's evening for you, right? You're probably 7 o'clock in the That's correct. That's correct. Yeah. Awesome. Awesome. All right. Uh I guess let's bring our guests on. Hello everyone. Hello. Hey. So, uh why don't uh you both introduce yourselves? Let's start with Tommy. My name is Tommy. Uh I'm an S sur here at Compass Digital and uh my primary responsibility essentially is uh ensuring the reliability, scalability and observability of our web platform. uh I work closely with the engineering team, product teams, test engineers to ensure that our systems are robust and we have actionable insights into what's going on within uh our services. So yeah, that's me. And where are you uh where are you calling? Oh yeah, I'm calling from Cambridge, Ontario in Canada. Awesome. We're we're like practically neighbors a few a few hours away from each other. Oh yeah. Awesome. Okay. And and then we have another Andre today. Um, hi. I'm out from Boneville Durm region. So, so same type of area. And uh, for me, I've been in this industry for 11 years, but always been since I was a kid and into the tech stuff. So uh I work with Tommy and the same team S3 at Compass uh digital here and uh very similar responsibilities across observability to um on call PI all the type of stuff for uh for our systems. Awesome. Uh well we're super excited to have you both on and just a reminder for folks watching if you do have questions along the way please feel free to post them on the chat. Um and also we will be taking questions at the end um if uh if anyone has questions. So I guess uh let us get started. So I know you guys both uh talked a little bit about um you know g gave your intros. Maybe you could talk a little bit about uh your respective roles at uh at Compass Digital in a little bit more detail. Sounds good. I'll start. Okay. Yeah, sorry. Uh I I'll go first then. Um as I said, um most of my roles primarily focused um on ensuring the reliability and scalability of our systems. Uh very recently or for the most part that I've been here, I've been working on uh one of our products. It's a company I actually bought over is e-club um to help get you know observability into what they're doing there. Um and largely you know I work with things like uh AWS SDK uh the CDK TF rather and uh PA duty um we have observability back end data trace where we send all our open telemetry stuff to um so uh pretty much just S sur uh there's not nothing too crazy happening on there but uh I believe as we go um along on this podcast I'll get more um nuanced into what I do and how your architecture is structured and the stack there. Sounds good. And uh Andre M uh if you could elaborate a little bit on on your Yeah, certainly. So when I started with Compass about 5 years now, um I started off as a senior software engineer. So that's my background in software engineering less so on the ops and infra side but that's uh kind of been a new love with terraform and um services but um primarily about the developer experience the platform engineering aspect of it and more recently angle it's more about understanding the uh system that you can worry about uh and they'll tell us that linkability how potentially across that and give us the insights with our platform and a vendor that we utilize that with. So just to give you some pretty cool things is like identifying any services that are you know looping into each other for instance uh via API rather than just like calling it internally with a function. So it's more about just like setting up these guard rails um and looking into the optimization of our system. And the other aspect is because we are a microser shop uh it's uh it's been a challenge for us to get that context propagation and seeing all the services all together. Um and now we're able to kind of have that full aspect all together and actually run real um I guess business impacts and analysis onto that. Um yeah that's primarily an area I've been looking at more or less. Cool. Uh folks uh can you to start with can you tell us a bit more about about the system that you are operating? What is it what is its architecture? What uh programming languages are used and yeah u yeah how how it is deployed and and so on. Okay. So we have two products. So I'll talk about the one that I primarily focus on. So for us our main infrastructure and architecture all runs the 90 95% is all lambdas. We have about 300 plus lambdas in our ecosystem. We run hybrid of dynamotp with Aurora RDS and that's the exact thing progress and we're slowly getting into argate services. Um so that's a little bit different model but uh that's the primary architecture of our ecosystem you know the standard services like S3 HP gateway just standard service stuff that as ecosystem provides Tommy. Oh yeah. Uh on the E-Club side, what we have is a blend of Python and Django on the back end. Um and then JavaScript, TypeScript on the front end and we run everything on that side on AWS ECS which uh gives us that flexibility and consistency across all our environment. Okay, thank you. Um so our CI/CD pipelines automate the process of building those Docker images and then deploying them onto ECS so we can roll out those changes quickly and safely. uh but to you know do a quick walk through uh across this little diagram that I have here. Uh so imagine a user interacting with application. What they hit first is the load balancers that we have here and then uh it distributes traffic to the web service that we have on the back end which runs ECS and instrumented with the open telemetry uh SDK. Now as this web service this web service or web services begin to process this request uh what it does is to offload uh some heavy tasks or async tasks to this celery worker down here which also runs on ECS and is also instrumented with uh open telemetry SDK and uh thanks to the context oops typo context propagation here uh the trace context can flow seamlessly between the web service uh and the worker and um with the introduction of the open telemetry SDK now we can follow a request end to end from um inception to the end right and um both these services that's the web service and celery worker the emit traces logs um are metrics um and we sample them make sure they um they they have high cardality and they are batched also for efficiency and all these data that you know I'm talking about ascent to open telemetry collectors that run as a sidecar on um ECS to send this data to our obserility back end. So this is uh pretty much in a nutshell what the uh architecture on the e-club side of uh what we are doing looks like. Awesome. Thanks for thanks for that. Um as a as a follow-up question, you know, given given your your your system architecture, um what was what what were the top three problems that you were facing that kind of compelled you to um to go like you know to say hey I need observability. Oh yeah. Uh sure. uh I'm sure you know and uh probably everyone listening knows that observability in a distributed system is never a solved problem and uh some of the nuance challenges that we faced was again as I said distributed tracing um with microservices a single user request can touch so many services and background jobs and uh without distributed tracing it's almost impossible to reconstruct that full journey of a request from the user's end to you know the the response back to the user especially when something goes wrong right so for instance if a user says that they had a slow user slow order placement rather um we need to trace our request from the web front end the back end the salary workers and even to third party APIs and the introduction of open telemetry helps us stitch all these things together right and also have consistent context propagation um across all these boundaries and um one of the things that we were also looking at was performance monitoring because we rely on celery heavily on E-club for background processing. However, uh these things can be black boxes if you don't instrument them properly. So, we need to know not just if a task has succeeded but how long it took uh what resources consumed and whether it's causing bottlenecks along the way. um introducing celery with uh sorry instrumenting celery with open telemetry um required us to go you know with out ofthebox solutions uh again thanks for that um and to to be able to add custom spans and metrics to these things and um also error tracking um you know errors can manifest in logs traces or metrics um wherever and um the most important thing um for us at the time was to be able to correlate these things together so that's having your trace ID and span ID and logs and uh being able to look at that trace ID in the log and correlate it with an actual trace. Right? So a spike in error log sometimes might cor correspond rather with a specific trace or a drop in a metric that probably we're tracking. Right? So what we've done is we've worked to ensure that uh our telemetry includes enough context like as I said the trace ID request ID so we can pivot between the logs traces and the metrics um seamlessly. So um yeah that's what got us to where we are now. Awesome. Um Andre uh do you have other Andre uh do you have any anything else to add? Uh so for our end I think the primary problem again really was that context propagation because again the microser and distributed um nature of that. I think the other part that we weren't even really aware about is just how the system really behaves. So a big part of it is uh tying back into alerting. So depending on what vendor you use it might have automatic alerting but being able to provide that to our developers in our case uh via Terraform. So developers can open up PR, create their own alerts, and now we have that across our ecosystems has really changed a lot of um how we're able to kind of empower the different developer teams to just take control of their own alerting and systems rather than um you know just one team kind of owning that. Uh can you tell us a bit more about how are your systems instrumented like what yeah what types of instrumentation are you using? Certainly. Uh so on uh our platform uh currently for us we do use our vendor uh agent. Uh so in our end um the agent's really nice for the most part. Uh it uh works seamlessly with both of our infrastructure pieces of for lambda. Lambda has the concept of a lambda layer where you can basically put on something. So their agent just goes onto that kind of bolts right on and works essentially right out of the box. Uh and the second part to that that we had to play around with a little bit was our ECS Fargate. Uh there is a solution from Adabus called uh adabus fire lens which allows you to kind of have your task um logs uh standard error and center out to basically be sent to a specific um sidecar where then that sidecar will run something like fluent bit or um they cubit uh and essentially take your logs and ship them to where you need them. Yeah, that makes sense. Uh I would ask a followup right away. Uh so are you using hotel out auto out auto out auto out auto out auto out auto out auto out auto out auto out auto out auto instrumentation or are you manually instrumenting your your services? So for us so because we do have the 300 lambdas each one need we basically have like a core library that all these lambdas will all utilize very thin layer but in there we do have um hotel instrumentation for the Node.js JS I believe it's just the auto instrument or I think we might uh we might have changed that for the finetuner because it needs to be small uh because lamp is you want to keep them really tiny. So I think we we do have the um uh the custom one where it's not the auto instrument and uh yeah how was how was the how was your experience with with doing that so far? Uh I haven't heard any um issues. So I didn't do that one. It was actually our coworker Matt who did that one, but I didn't see any too many I didn't see any issues with that. PR went through pretty smoothly and uh the prim primary purpose was we use our own custom logger uh one that isn't supported by um hotel or vendor. So we had to use that to kind of pull in the trace ID from the um headers and everything else and be able to actually populate the spans that we require. Cool. So, so to clarify then in in a nutshell, you you basically have like a wrapper around hotel from what it sounds like. Uh kind of it's um I guess so. Yeah. Yeah. I guess so. Yeah. Cool. Cool. And um question for you around uh just to keep on the instrumentation thread um who is responsible for instrumenting? Well, that's that's an interesting journey. So we actually do have a new project upcoming. So the way our system has kind of evolved um with Terraform in particular is you know we're IA first for no matter what we do infrastructure as code and a big part of that is we use the cloud development kit extension on Terraform. So it gives us the ability to kind of have this interherence model and allows us to build these L1 L2 constructs. Um so if anyone's familiar with that it's a very useful way of uh I guess building abstractions for your infrastructure and enabling teams to kind of um handle that as well. So uh in our case what we're trying to build right now is kind of an L3 construct which is like an application service um level where we can give it to developers and they can essentially have all the nuts and bolts kind of already instrumented out of the box uh with the right permissions and the right access and the right agents and everything else. Um, and we kind of support this golden path for them. Awesome. Um, Tommy, do you have anything else that you want to add? Um, no, not really. We, as I said, what I think we're trying to get to a point where all of these things are, would I say, prepackaged for the devs to be able to um to use them, to leverage them, to do their own instrumentation on their own. And um I would say for the most part we are automating um many of the um many of our collector setup or the open telemetry setup. But uh I think at the beginning what we did especially on the e-club side was to auto instrument so we can have quick wins and and move quickly. But um when we're getting down to things like business logic um salary tasks and things that were unique to the e-club side, we manually created spans along some critical code paths um and added some custom attributes here and there so we can um get more than just what open telemetry offers out of the box. So I think um for e-club it's just a little slightly different from u what we have on the centric side. Nice. Nice. That's really cool because I think that's a path that a lot of organizations start with anyway. Like the auto instrumentation is that quick win and then it's like, oh yeah, we're we're lacking a little bit more. Let's go with the manual instrumentation. That's awesome. Um, we do have a question from uh someone in the audience from Buddha. Um, hi Buddha, nice to have you join us. So, uh, Buddha asks, are you currently using all hotel signals, logs, metrics, traces, profiles or a combination of them? Uh so we are using logs, metrics and traces. Uh so logs are coming through depending on uh which infrastructure piece. So if it's Fargate, it'll come through the AWS fire lens and fluent bit solution and then be sent to our agent sorry to our vendor. Otherwise if it's uh lambda it come straight from the um lambda layer agent um with the um yeah with the lamb layer. And then for metrics uh that comes in through a different connector with our vendor. they have a solution we install in our uh cloud environment and then it kind of pulls all the metrics over to that. Now profiles is interesting. We don't use profiles but uh the use case I think for profiles is enabling maybe uh common attributes or standardization uh and so we handle that through again our vendor has a solution out of the box uh that allows us to kind of set the schema and richer data as it gets ingested. Great. Um, and then another follow-up question from Buddha. And by the way, actually before I I asked that, um, there was a question from, uh, Manish, um, who's asking if we are recording the session and yes, we are recording the session. So, it should be available on on LinkedIn and, um, YouTube on demand after the fact. So, um, great question. So, uh, the follow-up question from Buddha was, uh, was this how you started, uh, or slowly built up to it? Um, who would like to take that one on? Um, was that one for like the terraform aspect or just in general? I I'm assuming it was for the instrumentation in general, I would say. Yeah. Uh, at least one for Tommy. Tommy had a fun time doing that. Okay. Well, um, this was not how we started. And for context, I I joined about 10 months ago. And, um, yeah, as time I joined, we did not have open telemetry setup anywhere, at least best of my knowledge. And um I know that some of yeah a couple of the motivations um for adopting open telemetry on our side was um standardization um to because we had like a patchwork of of monitoring tools like um logs metrics everything scattered all over the place but open telemetry gave us a way to now unify all these and to reduce uh cognitive load and then the interaction overhead that comes with that. Um and uh additionally we wanted to be vendor neutral you know um using op telemetry allows us not to be locked to a single vendor so I say um I know I'm getting into the motivations for why we adopted it but it also cuts back into um the fact that we did not start out that way slowly built into it and these were some of the decisions that drove um us to using of telemetry Uh yeah, I hope that answer question. I hope so as well. How long did it take you to to get into the point where you are at currently? Uh I'd say we're still we're still getting there, right? Um and if I remember correctly, we started somewhere around September. Andre, keep me honest here. And I think by March, we closed the chapter on that one. um from I would say from conceptualization but I say from implementation to when we thought that we were in a good place so roughly seven months right um trying out stuff and uh yeah I think we're in a good place now all righty uh yeah we have a we have a question in chat from Manish uh when we talk of open telemetry data there is always a huge amount of data how are you optimizing your storage and managing doing it. Uh, okay. I I I'll take this one a bit and then I'll let Andre finish off cuz he's the geek with that. Um, one of the things we do is sampling, of course. Uh, and I know when we query for stuff, we do a sampling ratio of I think 1 to 1,000 for traces at least on the E- Club side. Um, this is so uh this is tuned in this way to balance cost, performance and and visibility. And of course we monitor the effectiveness of this sampling setting and adjust it dynamically during incidents or specific services um that require deeper analysis. And for logs for querying um and most of the other things we do with logs we enforce a scan limit of 500 GB per query to keep the back end performant and cost cost effective. Um but I know again Android geeks out on on things like this. So I think you'll be able to give uh a better response. Technically we got a really big budget for our vendors. So we actually have uh zero sampling at the moment. So we just we grab it all. Um we're just trying to understand from that point and uh slim it down and um you know the first exercise that we we kind of ran through was grab all the logs kind of run like a pivot on it like the error logs do I count on uh you know sorry just general logs and are there any useless logs that are being constantly created by the system or just noise and can we remove that and the answer was yes so I think we had something like two billion three billion logs coming in that are just like success that we just didn't need to have in place for it. Um, so yeah, we could been cleaning up the system a lot. Uh, we go through all our pods and kind of hand out tickets to them as we find through the investigation and be like, "Yeah, let's get rid of this or uh you make it a debug log potentially if you guys actually need it, enable it during your debug sessions." Otherwise, let's not try to have too much noise uh into our ecosystem. I will say though that one caveat is because we are running Lambda that that one agent and Cloudatch requires certain logs to come out. So we can't get away from certain noise like right now I think we're ingesting 54 million logs a day um that we just we can't get away from and they're just noise at the moment. So uh another motivation to move to Fargate where we have a bit more control over system as we uh adapt a bit more of the observability ecosystem. Cool. Cool. Uh yeah Manish if you have any follow-ups feel free to feel free to post them in chat and I would continue with the next question about collectors can you folks tell us a bit about the way how you set up your collector or collectors what is the distribution and yeah what is the architecture overall super curious about that okay well I I'll begin again with the e-club side and again for context um as I said I I handle most of the e-lub side does pick stuff um concentric. Um and for E- Club, what we do is try to make our collector um environment aware. Um so in Sandbox, cuz what we have is Sandbox, staging and production on E- Club. So on Sandbox, we sample a little more aggressively to capture as much data as possible for debugging especially for me, right? To really know what's going on there and um also help the devs um really debug um stuff that they have going on there. But in production what we do is a little more probabilistic. I hope I got that right. To balance visibility with cost, right? And um what we do is we dynamically also adjust that sampling ratio um if there's an incident and then we temporarily increase that to capture more data. Um and again the collector definitely does all the batching filtering um and exporting telemetry to the back end our vendor. And uh of course this is done in a yaml config to define our pipeline for traces for metrics and log and to also set the environment specific parameters like service name the host type and then all the open telemetry options we want to set um on that. So that's what we have for our collector on club and uh as I said at the beginning it runs as a sidec car through the services that celery the um the jungle application also. So as a followup um on your um collector setup so um do you have um so I guess two two questions. Do you have a way to manage like a fleet of your your because it sounds like you have a number of collectors. Do you have a way to manage them effectively? Like do you use op amp for that or do you use like kind of a homegrown thing? And also do you do you use like a collector gateway um to like funnel all of your collectors into like a central gateway before pushing that off to your your uh observability? To be honest, not really. uh we just manage the fleet using ECS as I said and then um we run them outside car to our standalone services and the um environment variables that I said help us customize those things I said earlier which are the sampling rates um the exporter and the service names so we don't really have uh we don't really manage the fleets independently um or independent of our services we just run them as a sidecar and lets us do the rest for us Um, so I I think that's pretty much it. But we we also monitor the performance, right? Definitely. Um, things like the Q length and then we have some drop spans along the way. So we can scale them horizontally if we do need to. Um, but for um high throughput services like the I can't remember the name, one of our of our celery I think it's celery flour, right? Um we have of course a higher instance for that to manage um the size and scale of how things can be and to avoid bottlenecks. Um so yeah so do so just to clarify do all your um site car collectors then do each of them go directly to your back end? Oh okay got it. And it sounds like uh Andre M had a a screen share for us. Yeah. So um and just it's a visual essentially the same idea that um Tommy was walking through there. Um before we get started though, shout out to Sky Draw for anyone using that. The best platform for uh brainstorming ideas and a little whiteboard place. Uh but uh essentially the ECS Fargate again I was mentioning the ads fire lens configuration for us. um the management all of it comes back to Terraform. So that allows us to easily manage our collectors because even the configurations everything in code. So it makes that part a little bit easier. um if that's what you're trying to guess prelude to uh our vendor does have that uh instance within our um account but we don't utilize that as we found that uh sometimes the logs are being dropped either we underprovisioned it and we found that if we just directly send them straight to the vendor there wasn't any issues that uh we've noticed aside us losing some of the benefits of that additional collecting uh if we have to do some data masking or dropping those logs prior to um being sent and ingested by the vendor there. So, um definitely a area we're trying to balance. Um but, uh the other part is obviously the lambda, which again is super straightforward. It's just straight from the the lambda and straight to the vendor again um without any um additional pieces there. So, that may be an area now that we're talking here um area for improvement um because if we have those 54 million logs that are just noise, we might benefit by going to that uh filtering agent first. So very useful. Cool. Thanks for sharing. Yeah. Um you already mentioned uh this like areas for improvement and I'm wondering uh do you have any challenges with open telemetry currently and any any thing that uh perhaps the project could could do better to to serve you as a as as its user? Well, I'll say for me one of the biggest challenges was just initial setup, right? Uh configuring the connector and ensuring context propagation across all the services which required me to do you know manual instrumentation and uh of course there's a learning curve uh telemetry is powerful uh but again the API office is just so large and uh of course with in terms of best practices we are still evolving. Uh, one of the things that I'll probably like to see, um, and I think I'm speaking to the community when I say this is, uh, maybe more complex example project, speaking to myself too, of course, putting it out there. Um, but I would say the community has been has been really helpful, right? There there were so many things that I benefited from from GitHub mainly and then uh, a bunch of articles that people have written on medium, right? So, um, for me it's just more real world examples, more complex setups like probably what we have. Uh, maybe, you know, somebody just doing something that that big and putting out there for anybody to be able to use, but it say for me that's just been the the challenge. Um, not nothing too crazy. Andre, what about you? Do you have anything in mind? Um, not so much I can give feedback to really improve. I mean the whole uh time has just been learning learning learning right there's just a lot um I mean it's first exposure to it really for me it's not even that I had experience with other observability tooling it's just like straight to our vendor and then also hotel so just learning the best of the best right off the bat basically right uh and then learn the history so for me it's just it's been a constant um uphill battle to learn all the different intricacies um probably just want to echo Tommy's um message just more examples right being able pull things down, play with it. Uh getting into your hands really quickly. That's that's usually the best place to uh to learn. Yeah, I I totally agree. I think uh I think we're at we're open telemetry has been around long enough now that I I think many organizations are kind of past that 101 phase and are are eager to get into like the the more gnarly use cases. And and that's why, you know, we really appreciate folks like you jumping on onto these Hotel Me sessions talking about like your mature hotel setups because it really really helps others in the community. Um so we definitely appreciate that. Um switching gears a little bit. Um we were wondering um if you could uh if you have had any like interactions with the um hotel community um things around you know like you know if you got stucker in on on a particular issue like how how did you go about it if you got stuck like did you did you uh go on Slack or did you like Google stuff? Um how how how did that work for you? Uh I remember the first thing it was for E- Club. Um when we were trying to instrument it originally it was uh there's an extension we use for is it parallel processing Tommy? Do you remember that one? It's not uh W's wake there's another one. Well it's a Django app that we run. Uh and the problem with that is that uh there's an extension we use uh I think it optimizes performance and the problem with that is that it somehow was fighting hotel. Um yeah uh um I really can't remember the name but then I I I know they were fighting for the um thread the threading running in the background. Uh I think that that was one of the challenges that we had in the beginning. I really can't remember what specifically was but uh I know that was a big uphill battle back then. Yeah. So we had a open I think issue on GitHub with that. Um but uh luckily our vendor was able to um get their agent working so um it worked for that environment but I think um I think it's issue is still open but wasn't sure if it was like upstream with Django or was it so much with hotel itself. Cool. Cool. Um yeah thanks for that. Um, as a followup, um, have you gotten to the point where you have made any contributions to hotel, um, or, uh, or planning to make any contributions? 100%. Uh, nothing yet in terms of contribution uh, commit, but 100% we'll probably be looking at something uh, within the ecosystem of um, probably node or go, one of those two. Awesome. Um, final thing. So, I I think we've we've covered I think most of the um most of the the the base questions. We do have a a cool audience question that came in um from Esther. Uh it says, "How do you see open telemetry evolving in your workflow over the next year?" Really great question. H that is a it's a tough question. So well because I mean open telemetry I mean it's more about is it so much like the framework itself or is more about the data we're getting out of it because for me I think the the value I mean both both are great right because one gives us a standardized um tooling and framework to be able to switch vendors or anything else we have the capability now but for me I think the real value comes into what type of data do we really pull out of that open telemetry uh and what can we really get from it um I think that's where real value is. So being able to now take that data and apply user journeys and business events like those things I think are where um our organization can really uh I guess expand or benefit from for the most part. Mhm. Tom, do you have anything to add? uh not much but uh I think just like open test metro also keep maturing in our observability journey especially around logs and for complex setups like accelerary um or serless that's with lambda because I know there were there were also some battles fought there uh I also think we are probably going to have more out of the box integration um and tools to simplify the configuration for our collector right so I mean the ecosystem is growing so fast. So, um I would not be surprised to see us adopting it um a little bit more. Um as Andre said, we are growing every day. We are learning every day. Um but I think we'll be leaning more towards probably much better or more standard industry practices when it comes to um adopting hotel and uh using it to really observe our system. So uh that's what I see happening over the next year but who knows. Sounds good. Sounds good. Uh yeah we have more audience questions. Uh today we just we just uh talked over at the end with Adrian that we have really really engaged audience. So that's amazing. Uh so Manish is asking how are you doing the instrumentation of legacy systems? Is anything like that happening in like do do you have a use case for that? um think we have some older.net projects but it seems as if um our vendor supports out of the box and anything I think we even with that solution the vendor allows us to still have it in hotel format as it comes through. So um not really a concern for on our side from what I've seen so far. All righty. All righty. Uh and uh one more from Buddha. Uh how do you report on business value metrics for decision makers? What metrics do you report on? Yeah, I know I think Tommy you mentioned it that for that business logic you had to do some manual instrumentation. Can you tell us a bit more about that? Yeah. So, as I said earlier, there were um certain business logic that we needed to especially on the salary side cuz that's where we upload um stuff to um to really see how um data was flowing through that and then report on I think specifically it was it was a reporting service or I think an order service at the time. Um so what we got out of that really was just the rise and fall or the spike of um the would I say the others process within that within a certain period or within a certain trace. Um but you know reporting back to business people I think that one comes more out of the box with our um vendor and um we as Andre said build stuff that aggregates the amount of logs that we use um that translate into how much we pay for these things even though we have a big budget you know we we still don't want to be we still don't want to end up overshooting that um but I think again Andre would have more context into this cuz he builds most of the stuff that I report back to business leaders and that that's something he's so in love with. So I I would allow him take the floor on that. So I think for me the biggest one at least it's been months in development is um the most important key metric I've come to love recently is um users. So what is a single user doing across a system and aggregate that over a certain period of time. So um that alone allowed us to find a particular leak where we had a single user was a bug in our client uh and within our service uh that wasn't like a batch request where this one user within a short period of time was invoking over 200,000 requests into our system and with lambda pay as you go it's not a good uh not a good model there. So without this observability in place, we wouldn't even know that there is, you know, one single user somehow invoking 200,000 requests within like a six-hour period. Um, so these tips, it's small little things uh where now we can focus on a single user or aggregate it across a grouping uh and be able to find behaviors and it's really good when you throw into like a time series or flame graph and you can see these kind of like fat spots where you can just visually identify something doesn't look good here. Investigate That's great. Um, thank you so much um both of you, Andre and and Tommy for uh for joining us and and thank you to my co-host, the other Andre um for joining uh and um and also this is uh Andre K's first uh first time on on a stream. So like big uh big kudos. Um, awesome job as as co-hosts. So, I want to give a shout out. Um, and you know, as always, we appreciate all the stories that we hear from our community members showing how they use open telemetry out in the wild. It really helps us. Um, and it helps show folks in the community like, you know, open telemetry is here to stay. We are we've got some like gnarly use cases of it being used out in the wild and it's it's great to hear those stories. Um, coming up next, stay tuned. We should have uh another Hotel Me planned, I think, in July. So, stay tuned on the hotel socials for that. Um, in the meantime, um, coming up at the end of this month, we have Hotel Community Day. Um, it's part of, uh, Open Observability Con. So, it's it's, uh, combined with Hotel Community Day. So that's happening um on the heels of Open Source Summit in uh Denver. Open Source Summit North America in Denver. So if you're around for Open Source Summit, check out Hotel Community Day and Open Observability Con that are happening together. And I think we've got a couple of CubeCons also um coming up. We've got I think I want to say this week is CubeCon um China. And then next week, I'm actually jetting off to Japan at the end of this week for CubeCon Japan. Um, and it's the first CubeCon Japan. So, very exciting stuff. So, if if anyone's around um for CubeCon Japan, come say hello. We'd love to uh would love to to meet you and talk. Um, and yeah, I think that is a wrap. And again for uh for those who attended tell your friends if they missed it the recording will be available um both on LinkedIn YouTube also check out the hotel end user s also have a um uh a group on uh on CNCF Slack we are called um I think we're called-ig- user so come share your stories on the hotel and user sig um chat and also if if you'd love to join us for one of our meetings. We meet every two weeks, so I think our next one is next week. So, yeah, thank you everyone once again for for joining and we'll see you next time. Thanks so much for having us.

