# OTel in Practice: Alibaba&#39;s OpenTelemetry Journey

Published on 2025-07-16T20:50:15Z

## Description

Join us for a new session of OTel in Practice with Huxing Zhang, Staff Engineer at Alibaba and OTel Go Compile-Time ...

URL: https://www.youtube.com/watch?v=fgbB0HhVBq8

## Summary

In this episode of "Hotel in Practice," Dan, a member of the End User Special Interest Group, hosts Hushing Jang and Steve Ra from Alibaba to discuss the adoption of OpenTelemetry within the company. Hushing, a staff engineer, and Steve, a senior software engineer, share their experiences transitioning Alibaba's observability tools from a legacy system to OpenTelemetry. They detail the migration process, emphasizing the challenges faced, the enhancements made to the OpenTelemetry Java agent, and their approach to compile-time instrumentation for Go applications. They highlight the benefits of the OpenTelemetry ecosystem, such as easier context propagation and better scalability, and discuss their contributions to the OpenTelemetry community. The session also addresses internal user adoption strategies and the importance of auto instrumentation in ensuring proper context propagation. The discussion concludes with an invitation for viewers to continue the conversation through community resources.

## Chapters

00:00:00 Welcome and intro
00:01:36 Guest introductions
00:03:00 Presentation begins
00:05:00 Background on Alibaba's observability
00:07:40 Migration to OpenTelemetry
00:10:00 Enhancements on Java agent
00:12:40 Context propagation challenges
00:18:00 Go applications instrumentation
00:24:00 Adoption cases overview
00:30:24 Future work and contributions

[00:01:36] **Dan:** Good morning, good afternoon and good evening whenever you're watching this or wherever you're watching this. Welcome to a new edition of hotel in practice where industry experts, end users and contributors tell us about a specific area of open telemetry and how it can benefit or it has already benefited end users. My name is Dan. I'm a member of the end user special interest group and I'm also a member of the governance committee and I'm very excited today to have Hushing and Steve to talk about adoption of open telemetry within Alibaba. I'm connecting from Edinburgh in Scotland. You can see the hills here. And if you're watching live on YouTube or LinkedIn, please say hi in the chat and tell us where you're watching from or where you're connecting from. Before we get started, I just wanted to cover a couple of housekeeping items. During the presentation, please drop your questions in the chat and although we'll make our best to get to all of your questions, I can't promise that we'll get to all of them. But fear not, if that's the case, if we can get to all of them and your question is not answered or you want to continue the conversation, you can go to the end user s and then we've got resources in this link and you can continue the conversation there. You find your way to Slack where we have a big community of end users including Hushing and Steve and we will be happy to provide some of their insights there. Also, please remember to keep the questions to date and topic of the presentation. And yeah, so with that out of the way, let's get started and welcome Hushing Jang, staff engineer at Alibaba and hotel compile instrumentation maintainer. Hi Hushing, can you tell us a bit more about what you do?

**Hushing:** Hello Dan. Very nice to meet you and hello. I'm Hushing. I'm from Alibaba. Yeah, I'm working as an observability engineer in Alibaba cloud and we are also working on the client instrumentations. So we work very closely with the open telemetry community. We're working on different kinds of language instrumentations, collectors, and something like that. We also provide service both for internal and external clients, customers. Thanks.

**Dan:** That's awesome. And also welcome Steve, Steve Ra, senior software engineer at Alibaba and hotel Java instrumentation approver. Hi Steve.

**Steve:** Yeah. Hi Dan. Hi. I am. I'm Steve. I'm also from Alibaba cloud. I work in the observability team in Alibaba and I participate in Java agent and I also responsible for profiling in our team and provide out of box profiling ability for our users. Thank you.

**Dan:** Nice. Well, welcome both. I'm really excited to hear more about how you're approaching open telemetry in Alibaba and how you ended up contributing as well, being major contributors to open telemetry. So, now that we're all set, you've got a presentation and you'll guide us through it. I'm going to move out and then please take it away.

[00:05:00] **Hushing:** Okay. Hello everyone. We are Steve and Hushing from Alibaba and we are very glad to share our talk Alibaba practice experience. Today we will explain our talk from the following five parts and I will introduce the first two parts and the remaining are given to my colleague. The reason for choosing hotel. Let me briefly introduce our background. In 2013, we provided observability capability for our internal users by manual instrumentation and we provided this ability into our internal software frameworks and we also designed a set of trace propagation protocol called Eagle I. In 2017, we developed the Alibaba Java agent based on the pinpoint Java agent. After several years of use, we found some problems such as pinpoint cannot support verifying the supporting version of a framework. For example, if a framework released a new version, the instrumentation may not take effect and we can perceive this immediately. Another thing sounds like pinpoint cannot support very well in some scenarios such as trace propagation synchronously. It doesn't support it automatically and there are also some other reasons due to the limited time I cannot list them one by one. 

From 2020 to 2023, we researched some other solutions from open source. At the time, we found open telemetry is a very strong ecosystem. It has rich semantic conventions and it represents the standard in observability. After several internal discussions, we made up our mind to migrate our Alibaba Java agent from pinpoint to open telemetry. After several months of development, we launched our Alibaba Java agent based on open telemetry in 2024. We also launched our Golang and Python instrumentation based on the semantic convention or SDK. Currently we embraced open telemetry completely. 

[00:07:40] After introducing our background, during our migration, we really did a lot of enhancements on the hotel Java agent. The first one is instrumentation. At the time we found open telemetry not widely used in China because there are some frameworks that are not supported by the hotel Java agent but they are widely used in China. We had supported them before. So we needed to implement them based on the hotel Java agent architecture. The second point is profiles. As we know profile is a very powerful tool. It can help us to inspect the behavioral performance of our application at runtime. It can help us to know which code is responsible for the spikes in CPU memory usage. We have supported profiling for several years. So the migration of this feature is also very important for us. Other abilities such as abundant sampling or more metrics and we also need to debug a very popular debugging tool in China. Last but not least, we not only support observability by Java agent, we also support microservices governance such as traffic control or security management by this Java agent. 

[00:10:00] So how to combine them in the hotel Java agent architecture? It's a toss-up we need to solve. Due to the limited time at the time and how to migrate them, it's challenging for us. In fact, at the time we weren't very familiar with telemetry and in order to achieve this goal, we came up with a two-step solution to solve this question. First one, we forked a copy of the Java agent repository and we promptly implemented all our commercial enhancements on the Java agent. In this process, it's not very easy because there are a lot of commercial features. If we migrate to the open telemetry, there are a lot of issues or problems and due to the rich business scenarios and during migration, we also found some problems and we needed to fix them and some of them are strongly related to the upstream and we also contributed them to the upstream. After about six months from research to launch the first release of our Alibaba Java agent based on open telemetry. After finishing this phase, we knew that it's not enough because we know the biggest charm of open telemetry is its stronger ecosystem. If we compare our code with open source, it's challenging for us to merge some upstream updates to our Alibaba Java agent. 

So on the one hand, we promoted our users to use our first version and then we also invited some developers to design some extensions or use some extensions from open source to migrate our commercial feature. This process is time-consuming because we need to design some extensions based on the Java agent and we also need to contribute them to the upstream. The other things we are currently doing, after this step we can see the open source hotel Java agent just like a dependency for us and we can decouple our commercial code and the open source code and we can merge upstream easily. 

[00:12:40] This is our whole approach to achieve migration. After migration to open telemetry, we gained a lot from open source and we also got something we didn't anticipate at the beginning. The first one I want to share is the hotel semantic convention. I guess that is the soul of open telemetry and when we migrated to open telemetry and we told our users we achieved this Java agent based on open telemetry and they can do a lot of things by themselves such as they can search some materials, some documentation by themselves and they can learn how to use some extensions to write something by themselves and they can debug some problems by themselves. I think that is a very good point for us to embrace open telemetry and our users can do a lot of things by themselves and it rarely reduces users' learning burden. Because they just need to learn the standards, the semantic convention or implementation of open telemetry and they can do a lot of things by themselves. 

This is the first point. The second point is good architectural design and better scalability of hotel instrumentation. It's very useful for us to promote our users to use our Java agent. How to understand this? For example, before Java hotel Java agent, if a user used a framework that is not widely used and we don't support that framework in our Java agent, they will create an issue for us and ask us to schedule resources to support this framework. But sometimes, we take the cost and energy into consideration, we are reluctant to support that. So how to communicate with our user that is a question at that time. Nowadays, this is not a big question. Because we can tell our users there are a lot of extensions; they can use this extension to support their own framework and they can do it by themselves and a lot of users are very interested in this because they can extend a lot of things by themselves and don't rely on us. 

This is all the things I want to share today. The remaining time, I will introduce something from other aspects. Thank you.

**Steve:** Thank you, Hushing. I will next introduce. Hello. Can you hear me very well? 

Yes. Okay. Sorry. There's some network issues. Maybe I just lost the connections. I will go into for the remaining part. 

[00:18:00] Yes. Actually, this solution has been started in 2023 and at that time we wanted to look for a solution that can be easily applied for Go applications for the to-do instrumentations. Actually, when we were trying the eBPF based approach that is already been provided by the open telemetry community, but it turns out that there are some limitations. We finally figured out a way to do the instrumentations to satisfy our needs that is in a compile time instrumentation. If you're looking at the figure on the right, there's an approach that the injection has happened in the middle of the compilation process. Actually, we hooked the Golang compile command to make sure that can be done for users without any modifications to users' code. That's a key feature that we want to achieve. 

Next, I want to address several highlights of this approach. First is the async context propagations. Actually, we encourage our users to follow the guidelines, but actually not all the users follow the rules. Sometimes they do not pass the context object correctly and the traces may break and become incomplete. So this feature can actually do the context propagation automatically for us even when we are not passing the object correctly. The second one is that it is actually compatible with the old SDK. That means that users who have used manual instrumentations can work well with our approach. So the traces can be merged. The last one is the most powerful feature that we have done is kind of like customer extension. That means that you can instrument any code into any point, any line of that application. This allows us to solve some special requirements from users. Then they can do some customizations like traffic management and security. 

Next, we will introduce some practices that we have in the LLM of observability. As we know, the LLM has been popular recently, especially this year a lot of AI agents have become active and there's a typical use case that we found. In the use cases, a user sends a request to the API gateway and the API gateway sends to the LLM applications, which are written in maybe Python, Java, or Go and the application will call different kinds of models, for example, DeepSea Queen or OpenAI. 

We have adopted an AI gateway in the middle that can do a lot of things for us. For example, it can do unified access and token limitations, token cache, and other stuff like that. We have adopted the open source project called Highress that can do it very well for us. 

When we are building observability across the different components, we make sure we're following this latest JNI semantic convention. Because the convention is still in development, we're trying to keep pace with them as much as possible. We have done some instrumentations based on this semantic convention. This includes major AI agent frameworks like high code frameworks such as AgentScope, Agono, Lang, Spring, Alibaba, etc. 

For low code platforms, DIY is a very popular open source project to build AI agents with low code. We also do some instrumentation for the official MCP clients. For example, we want to capture the MCP2 courses; we want to capture the M32 responses and to make sure our observability is end-to-end. We want to put our instrumentations into the internal models that come up with serving frameworks like VM or SGAN, which are actually Python processes running there. So we can put our Python instrumentations into that Python process to capture traces and key metrics like TTFT (time to first token) and TBOT (time per output token), which are very important metrics for us to identify bottlenecks of LLM serving issues. 

[00:24:00] Next, talking about the adoption cases. Actually, we have many adoption cases. I want to introduce several of them today. I divided them into two parts. The first part is the cloud service data flow. When users use cloud service, we make sure all the services that are in key positions of the application embrace the official W3 tracing goal by default. That means that balancer way or they support the W3 protocol by default. They will have the async messaging, like how a consumer is consuming the messages, to measure the latency or identify bottlenecks. They are using open telemetry to do that. 

For the AI studio, they are using Java and Python hotel instrumentation for end-to-end observability. The next part is the cloud service management console. A lot of management console services have embraced open telemetry as well. For example, the elastic cloud computing service is using hotel Java instrumentation quite a lot and they extend and make some extensions to that. They want to do request-based traffic routing. They want to route the service to different machine groups. 

The video on demand service is also running a large amount of clusters written in Go and they have adopted the Golang compile time instrumentation mostly for runtime monitoring. They want to monitor the runtime metrics and also provide data. Another case is the institution detection service. Thereâ€™s an agent running on the host written in Go. Before open telemetry, they had nothing to do with observability because they lacked techniques and tools to do that. Now they can use hotel Go compile time instrumentation for their runtime monitoring and profiling. 

As our own service, the cloud monitoring service also implements self-observability with Java instrumentation. We do a lot of things with Java instrumentation to do traces and profiling. This is a good example of dogfooding, right?

Yes. Besides our internal adoption, we are also trying to contribute these enhancements or extensions back to the open telemetry community. We have mentioned before that a lot of instrumentations, some of them have been contributed and some are also on the way to contributing back. We also helped promote open telemetry in the APAC area. We helped organize some meetings that are friendly to the Asia-Pacific areas like Java, Go, and Jingi meetings. We also engaged with conferences like KubeCon and the hotel community and we are also organizing events like KCD to help promote open telemetry in Asia-Pacific areas. 

In 2024, when we decided to donate this Golang compile time instrumentation to the open telemetry community and after a long discussion with the community, we also found that DataDog showed a very strong interest in this project. They actually submitted a proposal to donate their own framework, which is also a compile time instrumentation project, to open telemetry. So we decided that we do not want to depend on a single company's effort. We formed a special interest group (SIG) to build this project from scratch. This SIG is co-founded by Alibaba, DataDog, and Quesma. We have a common effort to implement this compile time instrumentation for Golang. This project is still in active development and we are working on the first release and the first MVP version of that this year. 

[00:30:24] If you are interested, please definitely check it out. Talking about future work, for Java instrumentations, we are planning to implement the proxy agent mode. That means that we want to use the Java agent as a dependency rather than booking upstream projects because we do not want to maintain such kind of project. We want to make sure all the extension points can be merged into the upstream so that we can extend this project very well. 

For the Golang compile time instrumentation, we are working well with the MVP version and we're making sure we are working towards the first release. We will also support more signals including metrics and profiles. For the GI, we also want to contribute some of the instrumentations back to the community because the GI is still in active development. We put some of them in our repo and we want to contribute them back as well. 

Actually, we also made our own open telemetry distribution called Long Sweet. Long is the Chinese version of Dragon. It's kind of a distribution built on various language instrumentation as well as our collector project called the Long Collector. We want to make sure that all the enhancements we want to contribute back to the hotel project as much as possible. But for some reasons, the community may not accept our contributions; they will be in our own distributions. 

That is all for the presentation and thanks for everyone for listening.

**Dan:** Thank you, Hushing and Steve. That was great. I think feel free to drop any questions in the chat and then, if you're watching live on YouTube or LinkedIn, I have one which is you mentioned the adoption of open telemetry within Alibaba. I wanted to know how easy was it for teams within Alibaba to migrate to open telemetry? Is there anything you can share in terms of facilitating a migration, maybe they use something like a common set of libraries or migration script or something else?

**Steve:** Yeah, I think it's not quite easy actually. It's not quite easy for them to migrate. We have done a lot of things to advocate for that. First, we wrote some internal articles to share some of our practices, like how a team adopted this technology and how they benefited from that. Then we put that into the internal article to help promote open telemetry. Secondly, we actually wanted to try to minimize the effort for the user to migrate because we have a legacy project called Ecoi and they already have some instrumentations there. If we are switching to this architecture to the auto instrumentations, they might encounter some conflicts or something like that. We actually have done a lot of things to prevent such kind of things from happening and we built that within our agent with our instrumentations as much as possible to make sure the users have minimized their effort to start up and to migrate. The idea is to try to put things to our team rather than put the efforts to the users to make sure that a seamless migration from the old architecture to the open telemetry based one.

**Dan:** Nice. So you dogfooded that to make sure that you adopted it internally as well.

**Steve:** Yeah.

**Dan:** Makes sense. Okay. I think we've got some comments in the chat but no questions so far as I can tell. I have another one as well from myself. You mentioned that you run on the hotel Java agent stuff. You run a fork or a distribution of that agent but in terms of API usage, do internal users in Alibaba use the open telemetry API directly when instrumenting applications or do you have some kind of abstraction on top or a helper library that they use instead of the open telemetry API?

**Hushing:** I think for most cases, we would have them use the auto instrumentations as the first choice because that is less effort for them to start their adoption. But for some special cases, actually, we can't satisfy. We will encourage them to use the SDK to add some custom instrumentations. For example, they want to add some custom spans or metrics. When that happens, we encourage them to use the official open telemetry SDK as much as possible because that is well documented and we actually have battle-tested it with the latest version of that SDK. So we do not want them to build another abstraction layer on top of that. But there are special cases that we introduced, like LLM application observability recently. Our AI studio is using the open telemetry SDK; they found that they have to write a lot of code in order to add their instrumentations because there are so many things they want to capture in a span. So they have to write a lot of instrumentations. So they asked us if we can provide an abstraction layer for them to simplify their work to do their instrumentation. So in that case, we actually worked with them to provide a higher level of that SDK. Their instrumentation effort has been reduced and they are very happy to do that. 

**Dan:** Yes. So that's one case I can share, and for most cases, I think it's using the official OT SDK.

**Hushing:** Yes. And in terms of the API as well because it's got that decoupling of the API and the implementation, like you can always swap the implementation underneath with the SDK, right?

**Steve:** Yes.

**Dan:** I want to share another point about this question.

**Hushing:** Sure.

**Steve:** For our internal users, some of them, if we don't provide auto instrumentation such as C++ applications, we encourage them to use the API just like Hushing mentioned. Another point for Java applications, some users, as we know, if they use trace or span, sometimes that is a monitoring spot. If we just instrument some frameworks, some key methods and if the latency belongs to users' code, maybe they can't get the information why the latency is so long. During the traces, at this time, we provide out of box profiling ability. We correlate the traces with the profile and we can provide diagnosis for users to understand why the latency is so long and which code is responsible for the latency. So they don't need to use the API to instrument their own methods manually.

**Dan:** Okay. Yeah, that makes sense. Last question from me. Again, if you're watching and want to drop a question, feel free. Both of you talked about context propagation as something that has definitely improved a lot thanks to open telemetry instrumentation. I know this from experience, especially when we're talking about async tasks. However, sometimes it's still challenging in certain scenarios to make sure that internally in a service, the context is propagated correctly. How do you encourage teams to ensure that context is propagated correctly within not just across services but also within their own services? And also, do you know if they measure that in some way if context is broken somewhere or leaking?

**Steve:** Yeah, that's a good question. Actually, I think for our internal users, it's very difficult for them. Even if we provide guidelines or encourage them to do so, they may not follow this rule. There is very much opportunity for them to miss that or fail to follow that. To solve this problem, it's our team's duty to make sure all the possible ways of asynchronous context propagations have been propagated correctly by our auto instrumentations. That is the way we solve this problem. We have popular frameworks in Java, for example, the thread pool or some kind of similar scenarios, and we do the test to make sure that the asynchronous context can be propagated properly. 

There are other frameworks that are very challenging for us to do. For example, Reactor Netty or such kinds of frameworks are very high frequency for them to switch context and asynchronous is common for them. For this kind of scenario, we might have something working not very well or as expected. For this case, we would like to try and work with the community to identify the issue and try to fix it. 

**Dan:** Yeah, I used to remember the days where you had to pass a context object around in function calls and it wasn't pretty and it wasn't good either. I think auto instrumentation is the way to go and anything that can get done transparently is also always going to be covering more and resulting in better context propagation, right?

**Steve:** Yes. As long as the users stick to that automatic instrumentation approach, they will ask us if we satisfied this or make why did that happen? So they will come to us looking for help rather than doing it by themselves.

**Dan:** Indeed. Okay. I think that's all we have time for today. Thank you so much for joining us both Hushing and Steve. It was great knowing more about Alibaba's approach to open telemetry. Thanks to all that joined live on LinkedIn and YouTube. Remember that if you want to continue the conversation, we've got the end user SEG resources as part of the opentelemetry.io website. Feel free to continue the conversation there and hope to see you there as well. Thank you again, both, and see you in the next one.

**Hushing and Steve:** Thank you. Bye-bye.

## Raw YouTube Transcript

Good morning, good afternoon and good evening uh whenever you're watching this or wherever you're watching this. Welcome to a new edition of uh hotel in practice where industry experts end users and contributors tell us about a specific area of open telemetry and how it can benefit or it has already benefited end users. My name is Dan. I'm a member of the end user special interest group and I'm also a member of the governance committee and I'm very excited today to have Hushing and Steve uh to talk about adoption of open telemetry within Alibaba. I'm connecting from Edinburgh in Scotland. You can see the hills here. And if you're watching live on YouTube or LinkedIn, please say hi in the chat and tell us uh where you're watching from or where you're connecting from. Before we get started, I just wanted to cover a couple of uh housekeeping items. Uh during the presentation, please drop your questions in the chat and uh although we'll make our best to to get to all of your questions, I can't promise that we'll get to all of them. But fear not, if that's the case, if we can get to all of them um and your question is not answered or you want to continue the conversation, you can go to the end user s um and then we've got resources in this link and you can uh you can continue the conversation there. You find your way to Slack where we have a big community of end users including Hushing and Steve and we will be happy to go and um provide you know provide um some of their insights there. Also, please remember to keep the questions to date and topic of the presentation. And yeah, so with that out of the way, let's get started and welcome Hushing Jang, staff engineer at Alibaba and hotel compile instrumentation maintainer. Hi Hushin, can you tell us a bit more about what you do? Hello Dan. Uh, very nice to meet you and uh, hello. I'm Hushing. I'm from Alibaba. Yeah, I'm working on as a observability engineer in Alibaba cloud and we are also working on the client instrumentations. So we work very closely with the open telemetry community. We we're working on different kinds of language instrumentations collectors and something like that also provide service both for internal and external clients customers. Thanks. That's awesome. and also welcome Steve Steve Steve Ra senior software engineer at Alibaba and hotel Java instrumentation approver. Hi Steve. Yeah. Hi Dan. Hi I am. I'm Steve. I'm also from Alibaba cloud. I'm work in observability uh team in Alibaba and I'm uh participate in uh Java um agent and I also responsible for profiling uh in our team and provide out ofbox uh profiling ability for our users. Thank you. Nice. Well, welcome both. Um I'm really exciting to hear more about you know how you're approaching open telemetry in Alibaba and you know how you ended up contributing as well being major contributors to open telemetry. So, um, now that we're all set, um, you've got a presentation and you'll you'll guide us through it. I'm going to move out and then, uh, please take it away. Okay. Uh, hello everyone. We are Steve and Husinang from Alibaba and we are very glad to uh, share our talk Alibaba practice experience. Today we will explain our talk from following five parts and I will introduce the uh first two parts and the remaining are giving to my colleague. Uh the reason for choosing hotel. Uh let me briefly introduce our background in uh 13. We have provide uh observability capability for our internal users by uh manual instrumentation and we uh provide this ability into the our internal uh software frameworks and we also designed a set of trace propagation protocol called Eagle I and in 2017 We a developer of Alibaba Java agent uh based on pinpoint a Java agent. After several years of used, we found some problems such as ppoint cannot support uh verify the uh supporting version of a framework. For example, if a framework released a new version and instrumentation uh may not take effect and we can perceive this uh immediately. Uh another thing sounds like uh pinpoint cannot support very well in some scenarios such as um yeah trace propagation synchronously. uh it doesn't support it automatically and there also have some other reason due to the limited time I I cannot uh list them one by one. So from uh 2020 to uh 2023 and we uh research some other solution um from open source at the time we found open telemetry is a a very strong ecosystem. uh it has uh reach uh hotel uh semantic convention and it represent uh the factor standard in observability. Uh after several internal discussion we made up the uh mind to migrate our Alibaba Java agent from pinpoint to over telemetry. uh after several uh months of development and we launched our Alibaba Java agent based on of telemetry in 2024. We also launched our Golong and Python instrumentation based on old semantic convention or SDK. Currently we embraced of telemetry completely. Yeah. after introduce our background uh yeah during our migration we really uh did a lot of enhancements um on hotel Java agent. Uh the first one is instrumentation. At the time we found uh of telemetry not widely used in China because there are some uh instrument uh framework they are not support um from uh hotel Java agent but they are widely used in uh China. We have supporting them before. So we need to implement them uh based on uh hotel Java agent architecture. And the second point is profiles. As we know profile is very powerful too. Uh it can help us to inspect the behavioral performance of our application at runtime. Um it can help us to know which code is responsible for the spikers. um in CPU uh memory usage we have supported provide uh uh for several years. So uh migr migration of this feature is also very important for us other abilities such as abundant uh sampling or more matrix and we also need to uh debark um a very popular uh debugging to ours in China. Last but not least, uh we not only uh support observability uh by Java agent, we also uh support microservices uh governance such as traffic control or security management by this Java agent. So uh how to compel them in uh hotel Java agent u architecture? It's a yeah it's a tosser we need to solve uh yeah introduced the enhancement we need to do and um u due to the limited time at the time and how to migrate them uh it's a challenging for us in fact at the time we don't very uh for many with telemetry and uh in order to uh achieve this goal we We come up with a two-step uh solution to solve this question. First one um yeah we forked a copy uh Java agent repository and we pro promptly implement uh all our commercial enhancements on the Java agent. Yeah, in this process is not very easy because there are lot of commercial uh features. Um uh if we migrate to the um of telemetry there are a lot of issue or problems and due to the rich uh business scenarios and um yeah during migration we also found some problems and we need to fix them and some of them are uh strongly related to the upstream we also uh contributed them to the upstream. uh after about six month from research to uh to launch uh the first release of uh our Alibaba Java agent based on open telemetry. uh after finish this uh um phase and we uh know that it's not enough because we um yeah we know the biggest charm of open telemetry is it stronger ecosystem uh if we combat our uh code compared with open source yeah uh it uh it's challenging for us to uh upstream some to merge some upstream update to our uh Alibaba Java agent. So we uh on the one hand we promote uh our user to use our first um first uh version and then we also invite some uh developers to uh yeah to design some extension or use some extension from open source to u migrate our commercial feature and this process is time consuming because we need to design some extension based on Java agent and we also need to um contribute them to the upstream and u the other things we are having have been doing uh currently and u yeah after this step we can uh yeah we can see the uh open source hotel Java agent just like a dependency for us and we can decoper our commercial code and the uh open source code and we can merge upstream easily. Yeah, this is our u whole approach to achieve migration. Um after migration uh to open telemetry, we rarely get a lot of things from open open source and uh yeah we also get something um we uh doesn't anticipate at the beginning. Uh the first one I want to share is um yeah hotel semantic convention. Yeah, that I guess that is the soul of the open telemetry and when we migrate to open telemetry and we tell our user we achieve this Java agent based on open telemetry and um they can um do a lot of things by themsel such as they can uh yeah search some materials there some documentary by themsel and they uh can learn how to use how to uh use some extension to write something by themsel and they can debug some problem by themsel. I I think uh yeah that is very um yeah good point for us to uh embracing of telemetry and our user uh can do a lot of things by themsel uh and uh it's rarely reduce users learning burden. Yeah, because they just need to learn um the standards the semantic convention or uh implementation of optometry and they can um yeah they can uh do a lot of things by themsel. Yeah, this is the first point and the second point uh good architectural design and yeah better uh scalability of hotel uh instrumentation that it's very uh very useful for us to promote our users uh to use our um Java agent. Uh how to understand this? For example, uh before Java uh hotel Java Asian and um if a user use a uh framework that is not widely used and uh we don't support that framework in uh from our Java agent and they will create a issue for us and ask we to uh schedule resource to support this framework. But sometime uh we take the cost and um yeah take the energy into consideration we are reluctant to support that. Uh so how to communicate with our user that is a a question at that time. Uh now day uh this is not a a big question. Yeah, because we can tell our user there are a lot of extension uh you can use this extension to support your own framework and you can do it by yourself and a lot of users um yeah they are very interesting uh about this because they can extend a lot of things by themsel uh don't light on ours and uh yeah it's only but I was uh after things I I want to share today and remaining time to introduce something uh from other aspect. Thank you. Thank you Steve. Uh I will I next to introduce Hello. Can you hear me very well? Yeah. Okay. Sorry. Uh there's some um network uh issues. Maybe I just lost the connections. I I will go into for the remaining part. Yes. Um actually this uh solution has been started in 2023 and at that time we want to looking for a solution that uh can be easily for go applications for the to do instrumentations. Actually we when we are um we're trying we're trying the EVPF based approach that is already been provided by the open telemetry community but uh it turns out that there's something uh limit some limitations there and we uh finally we have figured it out the way that to do the instrumentations at to satisfy our needs that is uh in a compile time instrumentation If if you're looking at the figure in the right there's a approach that's the the in injection has been happened in the middle of the compilation process actually we hooked the golan compile command and to do to make sure that can be done for users there's no you modifications to users code that's a key feature that we want to achieve and the Next I want to uh address several highlights of the this approach. First is the async context propagations. Actually the users uh we we encourage them to follow the guidelines but actually not all the users follow the rules. So because they do not pass the sometimes they do not pass the context object correctly the the traces may break break and become incomplete. So this feature can actually can do the context propagation automatically for us even when we are not passing the object correctly. The second one is the actually compatible with the old SDK. That means that users have used have used the manual instrumentations they can work well with our approach. So the the traces can be merged. And the last one is the the I think the most powerful features that we have done is kind of like customer extension. And that means that you can instrument any code into any point any line of that applications and this allows us to to solve some special requirements from users. Then they can do some uh customizations like traffic management and uh security. Yeah, please. Yeah, that's what I I think is very important. And uh next uh we will do we'll introduce some a practice that we have in the LM of observability as we know that the LM has been uh popular recent rec recently especially this year a lot of AI agent has become uh active and there's a typical use cases that uh we found in the use cases is a user send a request to the API gateway and the API gateway sent to the ALM applications which is written in maybe Python, Java or Golan and the uh application will call different kind of models uh for example deepseek queen or open AI and there's actually in in uh we we have adopt uh like AI gateway in the middle and which can do a lot of things for us for example it can do unified uh access and do token token limitations, token cache and or stuff like that and so we have adopted the uh open source project called high highress that can do it very well for us. So actually u we when we are building the um observability across the different kind of uh components we make sure we're following this latest JNI semantic convention and the uh because the convention is still in development we were trying to keep the pace with them as much as possible and we actually we have done some instrumentations based on this semantic convention. Uh this includes major AI agent framework uh like uh high code frameworks like agent scope, agono, lang, spring, Alibaba and etc. And uh for low code platform like DIY is very is a very popular open source project to build AI agents with low code. And we also do some instrumentation for the official MCP clients. uh for example the we want we want to capture the MCP2 course we want to capture the M32 responses and to make sure our observability is end to end so we want to put our instrumentations into the internal models models that brings up with ser serving framework like VM or SGAN is actually they are a Python process running there. So we can put our Python instrumentations in into that Python process to capture traces and key metrics like TTFT time to first token and TBOT uh time per output token which is very important uh metrics for us to to identify bottlenecks of LM um serving issues. Yes. Ne next please. Yeah, talking about the adoption cases. Actually we have uh uh many adoption cases. I want today I want to introduce uh several of them. I divided into two parts. The first part is the cloud service data flow because when users they are using color service make sure all the uh services that in the key key uh key positions of the application they embrace the official W3 tracing gole by default. That means that balancer way or uh they have support the W3 W3 protocol by default will uh have the me using they're using open telemetry the async uh messagings like how how we how a consumer consumer is uh consuming the messages well and to measure the latency or the identifying bottlenecks they are using open telemetry to to do that and for the AI studio they just I mentioned in the previous slides and they are using actually Java and Python hotel instrumentation for end to end observability and the next part two is the cloud service management console. Actually a lot of management console service has embraced the open telemetry as well. Uh for example the elastic cloud computing service they using hotel uh Java instrumentation quite a lot and they extend the make some extensions to that and they can they will they want to do uh like ser request based traffic routing. They want to route the service to different uh uh machine groups to Yeah. And then they actually done a lot of things be beyond the instrumentations. Yeah. The video on demand service also they are running large large amount of clusters written in Golan and they have adopt the coline compile time instrumentation and they uh mostly for the uh runtime monitoring. Yeah, they want to monitoring the runtime metrics also pro providing data and another case is the institution uh in uh detection service actually they are there's a agent running on the host they're written in go and they want before open telemetry they have nothing to do with the observability because they lack of techniques lack of tool tools to do that. Now they can use hotel go compile time instrumentation for their runtime and monitoring and pro profiling. And the last we as uh our own service uh cloud monitoring service actually also uh implement self observatory with Java instrumentation. We do a lot of things with Java instrumentation to do traces and profilings. Yes. And this is good example of dog fooding, right? Yeah. Next, please. Yes. uh be uh uh besides our internal adoption, we also trying to contribute this enhancement or extensions back to the uh Otto community. uh we actually have u mentioned in before a lot of instrumentations and uh some of them has been contribute and some are also on the way of contributing back. Yes. Um we also helped uh to promote open telemetry in the APAC area. We help to organize some meetings that is friendly to the APAC Asia-Pacific uh areas like Java go and Jingi meetings and we also um engaged with the uh conference like KubeCon and hotel community and we al we're also organizing uh events like KCD and to help to promote the open telemetry in Asia. Pacific areas. Yes. And uh in 2024 is we when we uh have uh decided to donate the this Goline compile time instrumentations to the hotel community and uh after a long discussion with the community and we also found that data dog has showed a very uh strong interest in this project and they actually they also uh submit a proposal So to donate their uh oran framework is also a compile time instrumentation project to open telemetry. So we decide that we do not we we we do not depend on single one company effort from single one company but we form a sig and to build the this project from scratch. And so this SIG is co-ounded by the Alibaba data dog and the Quesma to uh we have a common effort to uh to implement this compile time instrumentation for Golan and this project is uh still this project is still in active development and we are going to we are working on the on the first release and we are working on the first MVP version of that and this year. Yes. And if you are interested, yes, please definitely check it out. And talking about the the future work, yeah, for Java instrumentations actually we we are planning to uh implement the prox proxy agent mode that that means that we want to use the Java agent as a dependency rather than booking upstream project because we do not want to maintain such kind of uh project. We want to make sure all the extension point can be uh merged into the upstream so that we can we can extend this uh project very very well. So for the go line in compile time instrumentation, yeah, we are actually we are working well with the MVP version and we're making sure we are very in the first release uh working towards the first release. We also will support more more signals including metrics and profiles. Yeah, for GI we we also want to contribute some of the instrumentations up to the community because this GI is still in active the semantic commission is still in active development. Yes, we we put some of them in our repo and we want to uh contribute in the back as well. Yeah. Yeah. Actually we also have our own make our own open telemetry distribution is called long sweet long is for chi Chinese version of uh dragon long yes yeah it's kind of distribution built on various language uh instrumentation as well as uh our collector project called the long collector. Yeah. So we want to make sure that uh all the all the enhancement we want to trying to put them uh contribute back to the hotel project as much as possible but for some reasons the the community may not accept our uh contributions they will be in our own distributions. Yeah. And uh that is all for uh the presentation and thanks for everyone for listening. Yeah, thank you. Um thank you Hushi and Steve. Uh that was great. I think um yeah feel free to drop any questions in the chat and then uh you know if if you're if you're watching live on YouTube or LinkedIn um have one which is um you know you mentioned like adoption of uh open telemetry within um within Alibaba and uh I wanted to know how easy how easy was it for teams within Alibaba to migrate to open telemetry is there anything you can share in terms of facilitating a migration maybe they use something like a you know common set of libraries or migration script now with code generation or something else. Yeah, I think it's not quite easy actually. It's not quite easy for them to migrate. We have done a lot of things uh to uh advoc advocate for that. First we wrote some like articles internals and to and to share the some of our practice how uh like a kind of team they adopt the this technology and how they benefit from that and then we put that into the internal article and to help them uh to promote this open telemetry. Secondly, we actually we we want to try to minimize the effort for the user to migrate from because we have a legacy uh uh project called called ecoi and they want they already have some instrumentations there. If we are switching to this like C architecture to the auto instrumentations they might encounter some conflicts or something like that. We we we actually we have done a lot of things uh to pro to prevent such kind of things to happen and we build build that within our agent with our instrumentations as much as possible and to make sure the the users have minimized their effort to to start up and to migrate. I think this the idea is to try to put things uh to our team rather than put the efforts to the users to make sure that simly seamlessly uh migration from the oxy architecture to the hotel based one. Yeah. Nice. So you like do food in that so to make sure that you know you adopt it internally as well. Yeah. Yeah. Yeah. Makes sense. Okay. Um I think we've got some comments uh on the chat but no question so far as I can tell. Uh I have another one as well from myself. Uh you mentioned that you run on the hotel Java agent stuff you run a fork or a distribution of a of that of that agent but in terms of API usage do internal users in Alibaba use the open telemetry API directly when instrumented applications or do you have some kind of abstraction on top or a helper library that you know that they use instead of the hotel API? Yeah. uh I I think for most the cases they we we we we would them to use the auto instrumentations as the first choice because that is uh less effort for them to start their adoption and but for some special cases uh actually we can't satisfied so we will uh encourage them to use the SDK one to add some custom uh instrumentations. For example, they want to add some custom spans or metrics. So uh when that we encourage them normally we use we use the official uh hotel SDK as much as possible because that is well documented and uh we actually we battle tested with the latest version of that SDK. So we do not want them to like build a another abstraction layer on top of that. But uh there's a a special cases that we introduced in like LLM application observabilities recently actually and they uh actually our AI studio that actually they are using the LT SDK they found it that uh they have to write a lot of code in order to add their instrumentations because they there's so much things that want to uh capture in a span like they want to capture very uh very in detail want to capture a lot of things. So they have to write a lot of instrumentations. So they ask us to we can provide actually provide an abstract layers for them to simplify their work to like to do their instrumentation. So in that case we actually work with them to provide higher level of that SDK. So they they actually that did work because the they their instrumentation effort have been like reduced and they are very happy to do that. Yes. So that's is the one case I think I can share and for most cases I think it's using uh official official OT SDK. Yeah. Yeah. And in terms of the API as well because it's got that um decoupling of the API and the implementation like you can always swap the the implementation underneath with the SDK right? Yes. Okay. I want to share another point about this question. Sure. Um yeah for our uh internal users some of them if we don't provide um auto instrumentation such as C++ application and uh yeah we encourage them to use the API just like yeah HI mentioned and another point for uh Java application um yeah some users um as we know uh if they use trace or spam uh sometime that is a monitoring like um spot uh if we just uh instrument some uh framework some key uh methods and uh if the latency um yeah belongs to users uh code yeah maybe they can get the information why the latency is so long um yeah during the two trace at this time yeah we provide out of box profiles ability we uh correlate the trace this with profile and we can uh provide uh diagnose for users to uh to understand um yeah why the latency is so long which code responsible for the latency uh so they don't need to use the uh API to instrument their own method uh manually okay yeah that makes sense um okay last question from from me And you know again the audience if you're if you're watching and want to drop a question feel free. Um both of you talked about context propagation as something that has definitely improved a lot thanks to open telemetry instrumentation and I know this from experience especially in when we're talking about async tasks. However, sometimes it's still challenging in certain scenarios to make sure that internally in a cont in a in a service that is the context is propagated uh correctly. Um, how do you encourage teams to ensure that context is propagated correctly within not just across services but also within their own services? And also like do you measure do you know they measure that in a in some way if you know if context is broken somewhere or leaking? Yeah, that's a good question. uh actually I think for our internal users it's very difficult for them to like even if you improve approve uh provide like guidelines or encourage them to do so they not they may not uh follow this rule and they there's very much opportunity for them to like to miss that or to fail to follow that. So I think to to to solve this problem is uh our team's duty to like to make sure the um all the possible possible ways of facing cross propagations has been propagated correctly by our auto instrumentations that that is way we want we solve this uh problem. So we have the popular frameworks for example in Java the thread pool or the uh some kind of similar scenarios and we do the test to make sure that uh in the in the bottom of the uh technique they can be a sync uh context can be propagated properly. Yes. And this is another uh frameworks it's very challenging for us to do. So for example the uh reactor netty or such a kind of frameworks actually they are very uh high frequency for them to like to switch in context and asynchronous asynchronous is common for them and the this for this kind of scenarios we might have something working not very well or as expect for for this case we will like to trying to work with the community or uh want to solve it. first of all to figure it out by ourselves and we as as we as at the same time we will seek help from the community and to like to trying to identify the issue and try to fix it and uh yeah this is the common cases I think and then I used to remember the day the days where you had to uh pass a context object around in function calls and it wasn't it wasn't pretty and it wasn't good either. And so yeah, I think auto instrumentation is the and you know anything that can get done transparently is also is always going to be covering more and resulting in better context propagation. Right. Yeah. As long as the users has uh stick to that uh auto automation automatic instrumentation approach they will like to ask for that. Have you satisfied this or make why why did that happen? So they want to they will come to us and looking for help rather than Yeah. do it by theirelves. Indeed. Okay. I think that's all we have time for today. Uh thank you so much for for joining us both Hushin and Steve. It was great like knowing more about you know Alibaba's approach to open telemetry and thanks for all that joined live in LinkedIn and and and YouTube and uh yeah so we've got the remember that if you want to continue the conversation we've got the enduser seg resources as part of the open telemetry.io your website and uh yeah, feel free to continue the conversation there and uh yeah, hope hope to see you hope to see you there as well and thank you again uh both and uh see you in the next one. Thank you. Byebye.

