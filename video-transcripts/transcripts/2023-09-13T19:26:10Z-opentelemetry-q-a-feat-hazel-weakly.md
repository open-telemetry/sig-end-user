# OpenTelemetry Q&amp;A Feat. Hazel Weakly

Published on 2023-09-13T19:26:10Z

## Description

Adriana Villela speaks to Hazel Weakly about Hazel's experiences with implementing and optimizing OpenTelemetry practices ...

URL: https://www.youtube.com/watch?v=wMJEgrUnX7M

## Summary

In this YouTube video, Hazel Weekly discusses her experiences with observability and OpenTelemetry, providing insights for novice users. The conversation touches on the initial challenges companies face when adopting observability, including understanding the need for meaningful telemetry and the tendency to over-instrument systems without clear intent. Hazel shares her journey of helping a company reduce unnecessary data collection and implement effective instrumentation, highlighting how cultural and organizational factors can complicate observability efforts. She emphasizes the importance of aligning observability practices with business goals and the need for effective communication between developers and stakeholders. The video also covers specific technical challenges encountered while working with OpenTelemetry, including issues with sampling, baggage, and the ergonomic difficulties of manual instrumentation in various programming languages. Overall, Hazel's insights underscore the complexity of implementing observability in real-world scenarios and the importance of thoughtful design in telemetry practices.

## Chapters

00:00:00 Welcome and intro
00:00:20 Introduction of Hazel
00:01:21 Observability definition
00:03:00 Instrumentation challenges
00:05:00 Cost-driven changes
00:06:25 Sampling methods
00:09:30 Over-instrumentation issues
00:12:01 Context propagation challenges
00:15:00 Convincing the team
00:18:00 Observability improvements
00:19:01 Anti-pattern discussion
00:23:00 OpenTelemetry support in languages
00:27:00 Baggage challenges
00:30:00 Ergonomics of instrumentation
00:34:30 Libraries for OpenTelemetry
00:38:35 Infrastructure management experience
00:45:00 Making the case to executives
00:50:00 Regulatory compliance challenges
00:56:00 Closing remarks and future events

[00:00:20] **Host:** Thank you. Welcome everyone to the OpenTelemetry Q&A. We have the pleasure of having our good friend Hazel Weekly come talk to us about her experiences with observability. Welcome, Hazel.

**Hazel:** Glad to be here! Very excited for this. Yay!

**Host:** I guess let's start with first things first because I know we still have a bunch of OpenTelemetry novice users just getting into OpenTelemetry, folks who join our end-user working group. From the perspective of somebody who's new to OpenTelemetry, can you share what that experience was like? What kind of landscape were you coming into? I guess for starters, drawing back on that experience, was the company at that point ready for observability? What kind of kick-started the conversation into OpenTelemetry in the first place?

[00:01:21] **Hazel:** I would say, so I'm going to start off with my definition of observability because it's slightly different. The definition from control theory would be like, can you understand this system from the input and the outputs? Fred Herbert might talk about the definition from cognitive safety systems engineering, and that one is much more about the work required and the process required for a group of people to be able to understand everything and actually understand the system. That's how they discovered and think about that. Mine is the process through which you develop the capability of asking meaningful questions and getting useful answers. It's a process because it's evolutionary, and the questions have to be meaningful to you—whatever that means—and the answers don't have to be correct, but they have to be useful. 

[00:03:00] So when I look back at the company when we were starting to think about observability, or rather like distribution, literally, what are the questions that the company is starting to ask from the perspective of the engineers? One of the questions the company was asking from the perspective of the managers and what was it asking from the perspective of the executives? From the engineers at one of the companies that were early adopters of OpenTelemetry, they had it and they had instrumented things with it, but more from the perspective of “we know we need this,” but they didn't necessarily have that motivation yet. They weren't asking the types of sophisticated questions that motivate people to add their own telemetry. They had a bunch of telemetry, and they had a huge amount of instrumentation, and they had just the volume turned up to 11, and no one was actually querying that information. 

What I was able to do was turn down that volume significantly. I essentially said, “You're not using this, and you're not asking any questions from your system.” So when you do, don't turn the volume back up; add that instrumentation in there with thought and intent. That was an interesting hurdle to happen because in a way, people would ask questions to understand the system. They were asking them to solve a problem, and consequently, they just wanted every bit of information ever so that whenever they needed it, they could just go through a giant stack of noise and find a needle, right? That's not really what OpenTelemetry is for. Online distribution is for, can you understand the state of your system to the point that you only collect what you actually need? That is, in and of itself, a second layer of understanding the system, and they didn't have that second layer.

**Host:** Right, so it sounded like they were instrumenting for the sake of instrumenting and just sort of throwing everything at the wall and hoping something would stick. 

**Hazel:** Yeah, that also sounds like a very “I came over from Vlogs and I'm used to being able to search everything ever” approach. They also still had logs, which is a surprise. Basically, nobody of course. 

**Host:** In terms of like, how did you convince them to kind of tamp it down and direct it, make it more directed so that it could actually work for them?

[00:05:00] **Hazel:** Convincing them to champion it down and turn the volume down was actually pretty easy. That came down to cost. They were about 300% over budget from the vendor, and so I said, “I need to get you under budget.” I actually have a very funny image from that time period where you see the ingestion at about like two to three hundred million events per day, and you know I'm trying to tweak it down to about like 200, 250, or like, you know, 180 to 250 million. That was with very, very aggressive sampling. Finally, I figured out a bunch of misconfigurations in the sampling information and dropped it to about like three to five million events per day. 

Once I had done that, they had concerns about, “Oh, what if I can't find something?” I said, “Well, do you need to ask that question?” Then we were able to actually start the useful dialogue of, “Now that you have a question you need to ask, go and build what you need in order to get that answer.” Naturally, that sort of feedback loop that you kind of need with observability, whether or not you need that feedback loop end-to-end is a different question, but that is currently what OpenTelemetry requires. 

[00:06:25] **Host:** I think that's really great because being able to know what questions to ask makes it a much more meaningful experience. In your words, not searching for that needle in the haystack. I want to go back to sampling for a second. So sampling to a sampling was, we did the sampling through two methods. We had the OpenTelemetry collector, and I'll show you now, but at this company, we only had the Honeycomb Refinery set up until we had that set up. At other companies, we've had the OpenTelemetry collector setup, and I've used that. My preference is actually to use both, regardless of whether or not using Honeycomb. 

The reason for that is because the OpenTelemetry collector doesn't have the best steel sampling configuration, and the OpenTelemetry collector has like the most open-source line economic sort of configuration setup to consent things to multiple sources and multiple sinks so that is actually really useful. I like to use that one, and then aggregate everything and send it to Refinery and then do useful tail sampling. But running two pieces of information is kind of complicated for a lot of people. It's not going to be a huge hurdle of adoption to like my current company. They use DataDog, and one of the challenges there is they're not at the point where they can ask sophisticated questions of their infrastructure. 

I'm really still more at the point of “Is it on?” The question there is, well, even if I set things up for success by switching us to the OpenTelemetry line instrumentation tooling and then still send it to the same place, we now need to run like the collector in multiple places or run like a collector and Refinery just in order to do the same thing that they already do with their built-in tooling. That can be a bit of a lift because rather than saying “install library,” it's “install a library and have like five things also.” 

**Host:** Going back to the first organization where they were sending like way too much data, after you convinced them to chill and do more directed instrumentation, what was the next sort of hurdle that you experienced?

**Hazel:** There was a notch hurdle there. The way that company structured work was very much the over-platformed thing, this little towards unusual, but they had like developer productivity teams, and they didn't really have a platform team. What they had were engineers that didn't do work. The engineers didn't do infrastructure stuff; they wrote additional code, and they would have a bunch of people working on build tooling and build other stuff like that. 

[00:09:30] The question was, in the way that they do work in order to adopt OpenTelemetry successfully, you would need to essentially build libraries for things or write stuff into the code in a way that engineers weren't necessarily writing their own instrumentation, and that requires working at a level of abstraction that OpenTelemetry is really, really difficult. You can't propagate certain types of information down to child spans very easily or really at all. Setting up baggage is still very difficult. 

I'm working with context can be really tricky. If somebody uses an async function, then you might drop that and have to reconnect it somehow, and if the lifetimes aren't like already set up nicely, people can even add their own instrumentation, and then it'll get dropped from something because they don't actually understand the full context of where it is. They're just random code, and they add something, but in OpenTelemetry, you have to understand the call stack, not just the functionality, and those aren't always the same.

**Host:** Interesting. So how do you get over that hurdle?

**Hazel:** At that company, I was never able to fully get over that hurdle. I just made it better. One of the ways that I made it better was essentially following through all of the spans manually and looking for errors. When I found errors, I would trace it down to the source code, and I would do that. I ran into a bunch of very small things of like propagating information wasn't correct. So it was probably the information of like the helper functions rather than the actual call sites to activate that. Then I had to fix like 500 small things. 

Even when I did that, I found that there were a bunch of places where these looking as contexts weren't being complicated, so functions were just being launched or, for example, calling tracing, and that was being disconnected from the actual whatever. Sometimes things had to end before they started or start before they ended, and that got confusing because the language that they were using, it's very easy to write code in that logic, and it actually is more correct to do it that way. 

But OpenTelemetry, in its design, is very much a chicken-and-egg call stack, a tree-shaped, which is really, really ergonomic for a language like Java. It's not necessarily ergonomic for languages that aren't like that. So like React is a really common example because it's a runtime that's asynchronous, and it's really difficult to write code in React to the deadline nicely. 

[00:12:01] I suppose a good one closer is a good example of one that doesn't work very well. Watch does work, but for a very interesting reason, and that is because the Rust language cares about lifetimes. So you think about the lifetime of your functions, and so you always know what those are, and those end up being the natural tracing point protocol stack-based tradition library.

In terms of what we were able to do and how I was fixing it was really mostly in guacamole and doing some weird clever things to pack into the language runtime in order to make things hit the semantic model differences between OpenTelemetry and other language things about calling code.

**Host:** So were you like a one-woman show doing all of this?

**Hazel:** So the other person on this was off on parental leave, so for the duration, I was actually one person. 

**Host:** That is mad impressive. Did you want to like pull your hair out some days?

**Hazel:** It was tricky. A lot of it was that one of the benefits of using OpenTelemetry is that you get like this intuitive sense of what the code is doing at runtime if you play with it enough. They had to sit there and kind of doodle with it and look things up and ask questions and get answers. You have to have that dialogue running, and I knew how to do that, and no one else at the company was doing that except like one or two people. 

**Host:** Wow, and so you had like a very small select power users, favorite people, and then you had everyone else who may not have even like used OpenTelemetry at all or even knew like a vendor in any way whatsoever. 

**Hazel:** Yes, and I would get an intuitive sense if one was broken and what was wrong or something, and I would say, “Hey, like this is an issue,” and then people wouldn't necessarily believe me.

**Host:** Interesting. So how do you end up convincing them that it is an issue, or could you convince them?

**Hazel:** I was able to take advantage of certain people of the things, and one of the ways that I did that was essentially my predicting things, and then my predictions would turn out to be correct, and then I would give a solution to the position, and then the solution would work. One was the database was very, very spiky, and I mentioned that this was going to cause some sort of issues. One of the reasons that the database was spiky was because we had like basically the disk would slow on a database, and so we sped up the disk on the database quite a bit. 

[00:15:00] When that happened, despite this level down, these sets were still very spiky in general, but despite going high enough to lock things down, there were small things like that added up over time, and people started to believe me a lot more when it came to certain issues. But other ones that were more fundamental in the architecture, I never actually got around to being able to convince people of that, and I actually ended up leaving that company mainly due to that.

**Host:** Interesting. By the time you left, did you find there was at least like they were getting more out of their observability at that point? Because of your efforts, did you at least see some positive results because of that?

**Hazel:** Yeah, I did. There was a lot better understanding of where they were with the observability. People had more of an understanding of how to use it. I had like a couple of things so that it was more useful. They had a lot of it, but some things were wrong. If the error stack was there, the error stack died at the wrong spot, so it wouldn't actually tell you where the error happened. It would tell you where you defined the OpenTelemetry like the tradition helper, which is pointless. 

So I fixed that, and then all of a sudden the errors were correct again, and people were happy about that. Then they would actually use it. I had fixed a bunch of things, and I had reduced the usage from like two to three hundred events per day or even maybe 50 million events per day to like right. When that happened, then people could continue to add OpenTelemetry and add instrumentation everywhere without running into the physical—they were going to blow their budget even more than their own work. 

That allows people to continue to add more instrumentation. 

**Host:** So then I guess there it seems like there wasn't an issue per se as far as like getting people to add the instrumentation at that point because they were obviously—they had already over-instrumented the system previously. 

**Hazel:** Yes, it was interesting. They had over-instrumented it, but only via auto-instrumentation, so there was very little manual stuff done, and the manual stuff that was done was often done in a way that made the questions you could ask relatively useless. So like one example was, there's like at the top of the watched halfway down when in the life cycle of the call stack is when they would get the user ID associated with it because of how the database calls worked. 

But the user ID was never propagated to the top, so it was actually impossible to figure out how many pages a user was visiting, like procession. These types of questions whether or not I usually like it's on the same thing over and over because the question we wanted to ask was, “How effective would database account should be?” But would it be effective to put radish there somewhere? Probably don't have a 60-second something TTL. We had no idea because we couldn't actually ask that question. All the information was there, but not actually in a way that made anything possible to look for. 

[00:18:00] Because you couldn't look halfway down the span in order to get this span of correlated with this one, so that tree—you can only ask for things on the same level and down and filter that way. They needed to fix that, but no one necessarily knew how to, and no one necessarily knew that they wanted to because they weren't asking that type of question. 

So I brought that up, and then people started to get more of a sense of, “Oh, here's kind of where we put the information in a way that's visible.” To this day, I still don't have like a really good way to explain to people how to think about that other than you do kind of need to display the system. I couldn't understand where the data needs to be in order to be useful for asking questions.

[00:19:01] **Host:** Yeah, that makes a lot of sense. So yeah, that's so interesting. I find this such an interesting sort of, I don't want to use the word “use case,” but scenario, if you will. Because oftentimes we hear the stories of people just struggling with bringing OpenTelemetry into the organization and then starting to instrument, and this feels like it was like one giant anti-pattern—one giant OpenTelemetry anti-pattern—which I think is a very important thing to be able to discuss because, you know, like all tools, OpenTelemetry can be grossly misused, and then you end up with scenarios like this where you're instrumenting but you're not getting anything out of it.

**Hazel:** It was really interesting to see how this happened because a lot of what happened is due to how the company works and how it thought about working. It was very anarchic in the sense that engineers were very, very self-directed, and they would do things. The company had a huge cultural issue of intricate 80 percent done with instrumentation, maybe like 90 percent done, and then they would just drop off or someone outside traffic had to do something else, and no one else would pick it up. 

No one would sit there and make sure the things got fully finished, and so that essentially happened where we had one employee set up the main amount of instrumentation, and then one or two people added like some things to it, and one or two people added some things to it, but no one did like that last 20 percent of actually tuning things down. They turned everything on, they turned it all up, they added a bunch of things, and the only instrumentation, and then no one actually necessarily used it. 

For example, the OpenTelemetry instrumentation library was something they had to write because they used Haskell as a language. What that meant was they had each database query; they had four different spans. It would make a span from the start of the query instead of a transaction, an end of a transaction, and an end of a query. So you had, and then you have the command of a query itself. Every single database call cost at least four to five spans to appear.

**Host:** Oh wow.

**Hazel:** And there's no way to configure that or turn that down or cool unless things or anything like that. What happened was that word created, and then anytime you had like an N+1 pattern just appear instantly in the database, you would have given millions of events, millions of spans all over the place. They were like, “Oh, well, what do we use? Span events instead?” Most vendors either charge per ingestion, or they charge for like the telemetry that actually doesn't shift the cost anywhere. 

It sometimes meets the user interface slightly better, but it doesn't shift the cost, which is one of the reasons why people say, “Have one wide event when you put things in there, then like, you know, have timestamps and don't be afraid to use that.” But they were using the SDK essentially as the timestamp functionality to do a query event anytime, at any time, mark that something happened with a crazy fan anytime something happened, and it formed all the way down to the auto-instrumentation. 

That was tricky. That was probably like 80 percent of like, “Now we have instrumentation in the database,” but no one actually said, “Well, it turns out literally every other database SDK lets you turn 90 percent of the auto-instrumentation off,” and for a good reason. Same for like instrumenting the HTTP server, like the web server. You highlight the web server and then you have the web framework, and both of them had almost identical levels of instrumentation. 

Depending on which endpoint handler was in place, you either got one top-level or the other top-level or both, and so you had like a massive amount of certifications of the amount of spans that you might not need. It turns out it's largely because there wasn't really an ergonomic way to say, “Add this to a span if it exists; otherwise, create your own span.” That pattern is really necessary for libraries, and it's not actually really relevant in the SDK; it's not really mentioned anywhere, and it's not really possible for a lot of languages to do.

[00:23:00] **Host:** Right. Yeah, that is an interesting problem to have. So now when you were helping this organization with OpenTelemetry, how well-versed were you in OpenTelemetry at the time?

**Hazel:** I was knowledgeable of it, and I thought about it. I had done some things with it, and there had been like a previous company where I had really played with OpenTelemetry and React. I had set up like some very interesting and overly clever TypeScript helpers that made it really easy for people. I had familiarity there, but this company is where I had to really dig into the Refinery, into configuration, into operationalizing it, and to controlling the cost and understanding it from like that to the perspective of the operator rather than the end user. 

So that was an interesting change in perspective, and I ended up reading pretty much the entire RFC for everything, most of the SDK code, and a whole bunch of other things. I dug really, really deeply into it, and to this day, I will still not necessarily understand baggage. Like, I understand it, but it's kind of not well implemented.

**Host:** Yeah, you were mentioning earlier that it's funny because I was reading up on baggage today, and you were mentioning earlier that baggage is still kind of wonky to work with. Specifically, what were some of the challenges in working with baggage that you experienced? Because I think this would definitely be good feedback for the OpenTelemetry folks, the maintainers.

**Hazel:** It comes down to baggage is a really generic tool that ends up being used for like five different things, and they mostly come up when you want to stitch together multiple services or when you want to write a library or do something like that or write like a platform for people so that they can instrument things very easily and not have to worry about certain underlying implementation details. 

You can also use baggage to paper over the API of a lot of things and do what you want to even if you shouldn't necessarily do that. For example, package or just context application in general is more or less the only way you can have a directed acyclical graph. Otherwise, you only really have like a linear constant, and you have like some ability to form links, but even that is pretty under economic. But you need to know where you're linking to and where or what you're linking from. 

Baggage will let you like put things in a header so that you have cost service cost registration. The actual distributive part, the markets, is also the thing that you need if you want to navigate information down to public information upper chain, and there's also what you need if you want to write some sort of demand processor as a way to work around issues. So if you want to have like something added to multiple spans down, then the only way to do that, really, as far as I can tell, is to write a span processor and use this package to pull that information out. 

You would add something to the package and then ask the span processor if it's really thrown the spans, and it'll reconstruct that whole tree and figure everything out and then add that in there. You've more or less rewritten the Refinery in your code base, or rewritten the OpenTelemetry collector in your groupies in order to use packets in order to add certain features that aren't in the SDK yet.

**Host:** Interesting. Did you find that with other aspects of OpenTelemetry as well that were kind of limiting for you when you were working with it, when you were digging deep?

[00:27:00] **Hazel:** I think the main thing that was limiting outside of that aspect was that it's really hard to make adding instrumentation that's manual ergonomic. It's just difficult, and a lot of that comes down to OpenTelemetry really wants you to like have written the code right there, and you need to kind of know how to do that, and it's very hard to wrap the libraries themselves without adding like that extra layer of interaction that makes things hard. 

So unless your language has a very massive macro system and you can use that ergonomically, it's difficult to do that. Languages like TypeScript don't. In TypeScript, what you really want is something like a decorator; you can't get that. The other issue that I really ran into ergonomically with OpenTelemetry would have been based around async/await. The async/await one was probably one of the larger beams of my existence, and the reason for that is there's multiple different ways you can write, and especially as you're going to smoke, there is one way that OpenTelemetry works, and that would be if the parent function follows a child function. 

You're going to sleep, pass the context into it, and then waits and outlives the child function and then end-to-end span. So you have like a circuit historic, but actually, this only inside the lifetime of the parent's span. Anything other than that use case gets really weird.

**Host:** What about span links? Aren't they supposed to kind of alleviate that though?

**Hazel:** Span links do work, but you have to know how to use them. The parent still has to pull the child, and then the child has to have the parent ID in order to link to that, or I think vice versa. I don't know if you can do that, but essentially I couldn't write a function generically so I was unaware that it was being called from the parent and then had to link up to the parent. 

That was tricky because a lot of languages, you want to write like a library or something, and the library can be very agnostic. So I don't necessarily want to say this function is called pharmaceutical context all the time; I want to say this function is called basically in this context that's relevant to the application domain, and sometimes that's interesting context, and in which case it's been called asynchronously. But sometimes it's more synchronously, and sometimes it's called a different context altogether, and I can't express that with OpenTelemetry very easily, if really at all.

**Host:** Got it. And speaking of languages, what languages were part of that landscape in that organization?

**Hazel:** This organization had TypeScript and Haskell as its main languages, but I've also done OpenTelemetry with React. I don't know what TypeScript done with, and I've done it with a little bit of your name. I thought which one was the least annoying to implement? The least annoying to instrument would be probably Python because so many other people use Python, and Python is used in more of a service-sound context, and so OpenTelemetry is often used there. 

That was actually more ergonomic. Python also has like more decorators and metaprograms, how many things like that to make it easier to work with. It's interesting because it's both a front end and a back end, and so a lot of things that you can do with it may have to run both in a voucher context and server context. OpenTelemetry works really well on the service side and very not great on the client side. 

Dealing with all of those issues can be really tricky, and it may survive an API that works while I'm bullet is really hard to like on the client side. You want to send as little data as possible; on the service side, you want to send as much data as possible to the collectors so the collector can filter it. And so you have a completely need to there. You also have the issue of like how do I actually send data to the cluster on the client side, which is kind of solved, but not really. You end up like writing an API endpoint that supports things to the collector so that you can transparently authenticate or not authenticate in a way that actually works, and you can start to try and filter out noise signal.

**Host:** I guess someone calling the endpoint or are they just like—because of where did they answer something?

**Hazel:** I was reacting. The most annoying one to instrument or was there another language that you've worked with that was even more annoying? Haskell was the most annoying one to instrument.

**Host:** How big is like the OpenTelemetry support around Haskell?

**Hazel:** The OpenTelemetry support for Haskell is actually pretty decent, which is really funny because Haskell has a bigger usage community-wise than Master does for OpenTelemetry. Yeah, and so Haskell is an ergonomic language; it's very expressive, it's very interesting, but the one time of Haskell is absolutely absurd and makes OpenTelemetry extremely difficult. 

So Haskell is a funny lazy language, which means that if you write the code, you don't have any control over the lifetime of when the code is executed or actually evaluated or how deeply it's evaluated, and OpenTelemetry really, really wants you to explicitly call things, have it start, then have that happen and turn like point. 

In Haskell, laziness makes it interesting because you end up peppering the laziness with the ones of strict functions, which are the tracing stuff, and that can mess with your memory usage, can mention your performance, your interest, and it can match a couple of other things. It's very, very difficult in that language to have something include transparent; you want the tracing to be transparent. 

Otherwise, the tracing is really tricky and brings a bunch of other things, and so making it transparent actually requires the use of unstable primitives exposed by the internal implementation details of the compiler and the runtime.

[00:34:30] **Host:** Interesting. I feel like I learned something new today. I want to go back to another point that you had made earlier on, and hopefully, I understood it correctly. I think you made a point saying that generally organizations do tend to like create libraries around OpenTelemetry. Did I understand you correctly?

**Hazel:** Yeah, and it's not necessarily that organizations tend to do that; it's that that is one of the best ways to multiply efforts when you have like a platform team when you're thinking of things in a platform engineering manner. So in general, if you have like something people need to care about life testing or instrumentation or runtime performance or some aspect of the code that isn't necessarily functionality, getting everyone to care about that equally is really hard. 

It'll live on to have the same level of knowledge; it's really hard. In fact, it's kind of not even so much as impossible, but I think it's, I think, oh, people try too hard to hit, and consequently, it ends up being very, very useful from an organization perspective to accelerate your developers by having like libraries built around things or my platforms putting on things. 

So you have like maybe a standard template and then your instrumentations just don't work and your CI/CD is just dealt with, and a whole bunch of other things you're done with it, and you can use it, but these structures are already set up to give people capabilities for handling things, taking care of like distribution, so that cross-service instrumentation to support the box. All those things would be things that I would want to deal with from a platform team perspective of making telemetry easier to do.

**Host:** Yeah, that makes a lot easier at home really hard. So was there, at this previous organization, or even other orgs, even subsequent organizations, is that something that—it's one thing to, I think, have the aspiration to abstract that stuff from folks to, you know, make sure that they're at the same level when it comes to instrumenting. It's another to like be able to achieve that goal. Do you feel that in any of the organizations where you worked that that has been actually achieved with these kinds of libraries?

**Hazel:** I've been able to get things to a point where it was achievable; whether or not I actually achieved it is a different question. But so what I mean by that is I was able to figure out ways to like wrap and abstract away the vast majority of the setup for OpenTelemetry when I did TypeScript or Haskell, and I was able to write wrappers around functions in a way that the wrappers are transparent. 

So we could have like a bunch of environment variables properly in and a bunch of like sort of stand up for things dealt with in a way that people just needed to set up their application in a certain way, and then you got like the very base skeleton of the tracer and all those things were just ready to go. They can like get the, you know, without the span sort of function and have like a more limited understandable API where you didn't need to pass in certain types of contexts manually. 

I've been able to do that for both, and I've even been able to do that in a way that works isometrically in JavaScript or TypeScript.

**Host:** What does that mean?

**Hazel:** It means you can have the same code running in server and the browser, and it works. That involved a mild amount of crimes; it involved a lot of crimes. It involves a lot of crimes. I abused how Node modules cached a bunch of things, and then I imported certain globals and then the runtime certain stable code here and there. If you import everything in the right order in the right place and then you rely on trade shaking, then your bundle on the server can be different than your bundle on the client, and you can end up splitting that out in a way that doesn't break the global singleton pattern of observability of the OpenTelemetry stuff and also not explained anywhere. 

[00:38:35] **Host:** Switching gears a bit to more managing the infrastructure side of OpenTelemetry, how was that experience for you in contrast to having to, I guess, previous roles of being more, I guess, holistically focused or having to like clean up the OpenTelemetry mess? How was that in contrast?

**Hazel:** Running OpenTelemetry is interesting because like you have to open the OpenTelemetry collector to run, and the collector, like, then you have to set it up. If you go outside of essentially any of the very small documentation examples, you end up having to read the RFCs for things or you end up having to read the technical design document, and they are not obtuse, but they're understandable by like a select amount of people, and you have to really dig in to understand that. 

To like even for the tail sampling configuration of the OpenTelemetry collector, like an entire document of how to do it is the most difficult thing I've ever seen. It has like different layers of things; each one has its own entire language and specification setup, and it's wild. The Honeycomb Refinery is much better in that regard, but running Refinery in production is a janky mouse in a lot of ways, and that largely comes down to Refinery is really a tool that they built for themselves, and then they made it available to other people. 

So here's Refinery; if you know how it works, great, you just run it. But otherwise, you can run Refinery successfully if you're an organization with high-performance CI/CD, the ability to implement things and look at them, and you have that ability to like dial things down very rapidly. Otherwise, Refinery is not going to work super well for you, and to the organization that I ran Refinery in, split the difference; they had some amount of rapid CI/CD and some men of that, and I was able to look into logs and stuff like that and get some things down. 

But they used its pattern and Refinery due to how broken the OpenTelemetry stuff was. We ran into essentially every error case and edge case of it. For example, one of the edge cases that we had was many spans were not like, you know, a minute or two long. Finished spans were hours long or even days, and we had some spans that were multiple weeks in length, and we also had some spans that had over three to five million events in them. 

What ended up being was you would have something that would go, you know, I started to ask, and then that starts to span, and so this would be like an asynchronous job. Into the asynchronous job would, for every single user in the database, do a whole bunch of validation stuff, and so that would be about like 1,000 demands per user times 500,000 users or 20,000 spans per user times 40,000 users. 

It's ridiculous! Or like for every single item in the database, check its consistency in one span, so that would take like 20 hours, and that would break every possible configuration of Refinery. You just can't have this span that's not broken and also have Refinery store 50 million things in memory. 

I got things improved, and ultimately I ended up saying this entire way we do OpenTelemetry in like this with an asynchronous job is actually now close enough to streaming services that it doesn't work that way. The wheel dealer streaming services is to do it the way Honeycomb does, which is you just send a snapshot of this span every minute, so any rule of things in the code, and that requires you to have written your code in a way that you can roll things up and then send it every minute. 

You need to completely rewrite how you do most of your task handling to have some sort of task handling manager that sits there and can collect a bunch of things in every minute, do that, and start a new span. That is not really possible the way most people write asynchronous jobs, and fixing that is really tricky because there's not really a wheel if it's now; you're not actually just rewriting the code. 

It requires you to really just start a million different tasks, and each task is linked together casually by like span information. Then the collector sort of like does some things in there, or maybe your span processor can roll that up, but otherwise, you can't actually do that. 

Now, you should do your tasks in that manner anyway because then it allows you to have a right-hand lock, and then you can ensure your task consistency is a longer think. It's not interested in the middle; you should do that anyway because that's how you do it if you understand distributed systems. But you run into this thing in OpenTelemetry; it was written by systems-minded people, and so a lot of design decisions that they make make sense if you know how to write a standard stability system. 

Of course, you use a write-ahead log; of course, you want to just spawn an event from like respond one task somewhere for like 20 hours. Who does that? Everyone does that until they know better.

[00:45:00] **Host:** That's a really good point. We've got about six minutes left, but before we wrap up, I did want to talk briefly about some of your experience in trying to make the case for OpenTelemetry to executives because that can be challenging.

**Hazel:** Yeah, so there's two sides of it: there's making the case for any sort of monitoring or observability in general, and I was making the case for more OpenTelemetry specifically. The second case usually happens when you have some pre-existing stuff, and you're arguing, “We should not use the existing stuff; we should use this other thing instead.” 

What you're arguing for there is a migration, two migrations: a technical migration and a social migration, and those are very tricky. You want those both migrations to happen, and so you need to be able to essentially show that the time and effort saved by via this migration will pay for itself in about four months. If you can't show that it will pay for itself in about four months, then you probably shouldn't actually do it, and you should figure out how to make it pay for itself in four months and then do it. 

Otherwise, you'll end up with a migration that takes like a year or something, and it has no perceivable difference in benefit, and then people are not going to be sold on it. People need to actually tangibly feel the benefit, or the migration is going to feel on the social aspect technically. 

For conventional organizations that you want to get like any sort of monitoring in general, that relies on being able to convince people that the life cycle leads to encompass more at the life cycle, and the easiest way to do that is, in my opinion, you tie the code lifecycle to the business value delivery lifecycle. 

So what can happen in organizations is you have like the developer lifecycle, which is over here, and it's, “I write code, I commit code, I merge code,” and you have the business lifecycle, which is we could do some market research, or we get like some seamless research, and then we design a product, and we get the final features, and then that final feature is implemented, and then we see what the feedback is. 

At no point do those two overlap or cross. So that leads to people to my product owners handing features over to developers and developers writing tune and just handing lots of production. Instead of playing frisbee, you need to merge those. When those get merged, then essentially the developers have to care about things all the way to the point where it delivers value to the customer, which is absolutely what every executive already wants to have happen. 

The state they have within separated is what they think is like has to be that way, and the second is it's possible and even desirable to get developers to care about like the outcomes from the customers, get them talking to salespeople, and get them talking to product people. 

That will not only improve things for the product, improve the internet, but it'll actually improve the productivity of the developers and their experience and their ability to do this. That usually sounds executives, and you need this. 

The next checking after that is once they have, “You need this,” if they just look for like observability, they're going to get one of like three or four different vendors and probably going to end up an expensive vendor. You need to pick the vendor based on what the business needs and not necessarily what you like the best. Like for example, my current company, we have advanced monument compliance requirements. 

We have it for only one environment that provides more than one codebase, and so because of that, no one in the company can use anything that isn't FedRAMP compliant, which significantly limits the amount of advantage we can have to basically one, and I don't necessarily want to use that vendor necessarily, but I have no plans to migrate off of it. If I were to migrate off of it, it would be in a very interesting manner. 

What I would do is I would split the environment into two environments and have them be identical, one FedRAMP certified, one not FedRAMP certified, and then essentially would have a FedRAMP program, but that would be like a separate sales funnel, and anyone who actually needs it can have that because the FedRAMP is valuable in two aspects for the business. One is that it gets them certain customers, and one is that it gets some certain conversations, and for the conversations, those people may not be on federal, but they may want to eventually when it means that I can run the same codebase in both locations and use a different vendor and the one that isn't FedRAMP and that one but that whole migration for the current company would be allowed two years of work. 

Are we going to do that? Who knows? Maybe. But there's a lot of other questions to ask first and a lot more that we need to do before we can even get to that point.

[00:50:00] **Host:** Yeah, speaking as a vendor, we've had a lot of conversations about FedRAMP certification, and being that not 100% of our employees are in the U.S., we'd have to do exactly what you described. We tried to do that before for HIPAA, and it created kind of a weak experience for some customers, so yeah, it's a tricky problem.

**Hazel:** Interesting. I think one of the most interesting things about HIPAA is that any sort of regulatory environment—there's like one regulatory environment, and then there's like FedRAMP, and the overlap between people that need any regulatory environment and people that need or really want FedRAMP is basically a circle. 

So if you're going to go like, “Oh, we're going to have like a HIPAA environment, we're going to have a FIPS environment, we could have like, you know, SOC 2, like it used to be SOC 2,” whatever. But if you have one of those, you probably would actually get as much benefit, if not more, if you went straight to FedRAMP, even though it's like three times as expected to do that at least. 

And the ongoing maintenance burden of that is ridiculous, but it gets you on the other customers you need, like HIPAA plus FedRAMP or FIPS plus FedRAMP, and that is a really interesting business thing that's non-obvious. Any type of regulatory environment completely changes the game for OpenTelemetry, what you can do with it, how it works, your vendors in general, and even like your hiring practices, and it's really weird that you can't really have an asset, but you can't just get HIPAA; you really should probably go all the way to a FedRAMP just because of who the market is that needs one or both.

**Host:** I totally agree with you based on like our experience with that HIPAA server because it turned out there were companies camped on it that just had a desire for like more privacy, stricter controls because of how their company culture and their data worked without actually having the need for the federal regulation. 

I think you're right that it makes it easier to sell. I think probably we wouldn't end up going in that direction again unless we managed to partner with somebody who was actively like bringing in FedRAMP customers, like some agency that worked with the government or whatever, like we would have to be. But I wish we had known that at the start, and we didn't. 

One thing that would be interesting there would be to have OpenTelemetry have some sort of agency that—and that agency gets FedRAMP compliance. Then what you can do with that is you can have that agency essentially facilitate the onboarding of OpenTelemetry vendors or just other observability vendors into the space, and you can use that to sort of start bridging the gap and giving people more capabilities and sharing that my FedRAMP specific architecture concerns in the way that spreads their compliance load among multiple companies.

**Host:** That would be a really interesting idea. 

**Hazel:** Yes, it could maybe make it work through the project, and I would say for us as a small vendor, that really is a problem that if we are not allowed to have our engineers who are in other countries touch the system, we may only have one engineer working in a particular area, and so we have to hire a second person in the U.S., which is undoable. 

There are certain ways, and you would need somebody to talk to someone who's experienced in FedRAMP to negotiate that, which would have to be—100% U.S. citizenship is a non-seer own requirement. It gets nuanced, and it gets tricky.

[00:56:00] **Host:** Oh, interesting. Well, I think we have to leave it at that before we got into a funny side. Thank you again, Hazel, for sharing your insights. This has been really cool. I don't think we get to talk to too many people who have had like such advanced use cases for OpenTelemetry, and being able to share that with the community is really good because I think a lot of us get, you know, we do like those intro tutorials. We’re like, “Hey, that's pretty easy!” and then you get into like the guts of it, and then that's when you start getting into some of those gnarly use cases that can be really tricky in life.

**Hazel:** Yeah, definitely.

**Host:** So definitely appreciate that feedback and the viewpoint, and you will be back for OpenTelemetry in practice, I believe, on September 14th. Looking forward to that! 

**Hazel:** No idea. I'm going to figure it out, but it's going to be a lot of fun!

**Host:** Awesome! Really looking forward to that. Thank you again, as always, super, super awesome insights. Yeah, and we will hopefully see everyone for OpenTelemetry in practice with Hazel on September 14th. Thank you!

## Raw YouTube Transcript

thank you welcome everyone to otel q a we have the pleasure of having our good friend Hazel weekly come talk to us about um her experiences with observability welcome Hazel glad to be here very excited for this yay I guess let's start first things first because I know we still have a bunch of Hotel novice users like just getting into Hotel folks um who who join our um end user working group so from from the perspective of somebody who's new to open Telemetry can you share what that experience was like what kind of landscape you were coming into um and I guess for starters like drawing back on that experience um was the company at that point ready for observability like did that what what kind of what what kick started the conversation into into open Telemetry in the first place I would say um so I'm going to start off with my definition of observability because it's slightly different um the definition from control theory would be like can you understand this daily system from the input in the outputs and um Fred Herbert might should talk about the definition from cognitive safety systems engineering and that one is much more about the work required and the process required for a group of people to be able to understand everything and actually understand the system and that's how they like discovered and think about that and mine is the process through which you develop the capability of asking meaningful questions and getting useful answers and so it's a process because it's evolutionary and the questions have to be meaningful to you whatever that means and the answers don't have to be correct but they have to be useful so when I look back at the company when we're starting to think about observability and or rather like distribution literally what are the questions that the company is starting to ask from the perspective of the engineers and one of the questions of the company is asking for the perspective of the managers and what is it asking from the perspective of the executives and show from the engineers at one of the companies that are the early hand open telemetry they had it and they had instrumented things with it but more from the perspective of we know we need this but they didn't necessarily have that motivation yet the action weren't asking the types of sophisticated questions that motivate people to add their own telemetry they had a bunch of telemetry and they had a huge amount of instrumentation and they had just the volume turned up to 11 and no one was actually querying that information and so what I was able to do was turn down that volume significantly and then what I did was essentially say you're you're not using this and they're not asking any questions from your system so when you do don't turn the volume back up like add that instrumentation in there with thought and intent and that was an interesting hurdle to happen because in a way people would ask questions is to ask these types of semi's physical questions asking them to understand the system they're asking them to solve a problem and so consequently they just wanted every bit of information ever so that whenever they needed it they could just like go through a giant stack of noise and find a needle right and that's not really what open Telemetry is for online distributation it's for can you understand the state of your system to the point that you only collect what you actually need and that is it in of itself a second layer of understanding the system and they didn't have that second layer right so it sounded like they were instrumenting for the sake of instrumenting and just sort of throwing everything at the wall and hoping something would stick yeah that also sounds like a very I came over from Vlogs and I'm used to being able to search everything ever approach they also still had laws which is a surprise basically nobody of course so um in terms of like how did you convince them to kind of Tamp it down and direct it make it more directed so that it could actually work for them so convincing them to Champion it down and turn the volume down was actually pretty easy that came down to cost they were about 300 over budget from the vendor and so I said I need to get you under budget and so I actually uh in the honeycomb Pond eaters I have a very funny image from that time period where you see the ingestion at about like two to three hundred million events per day and you know I'm trying to tweak in and get it down to about like 200 250 or like you know 180 to 250 and that was with very very aggressive sampling and finally I figured out a bunch of misconfigurations in the sampling information and dropped it to about like three to five million events per day and um and once I had done with that they like had concerns about oh what if I can't find something I said well do you need to ask that question and then we were able to actually start the useful dialogue of now that you have a question you need to ask go and and build what you need in order to get that answer and then naturally that sort of feedback loop that you kind of need with observability which whether or not you need that feedback loop end to end is a different question but that is currently what open Telemetry requires I think that's really great because being able to know what questions to ask makes it for a much more uh meaningful um experience and so you know in your words not not searching for that needle in in the haystack I wanna um go back to a sampler for a second do sampling to a sampling was we did the sampling through two methods we had the open Telemetry collector and I'll show you now but at this company we only had the honeycomb Refinery set up until we have that set up um at other companies we've had the open Telemetry collector setup and I've used that my preference is actually to use both regardless of whether or not using honeycomb and the reason for that is because the open Telemetry collector doesn't have the best steel sampling configuration and the open Telemetry collector has like the most open source line economic sort of configuration setup to consent things to multiple sources and multiple syncs so that is actually really useful so I like to use that one and then aggregate everything and send it to Refinery and then do useful tail sampling um but running two pieces of information sorry is kind of complicated for a lot of people um it's not going to be a huge hurdle of adoption to like my current company they use um data dog and one of the challenges there is they're not at the point where they can ask sophisticated questions of their infrastructure and I'm really still more at the point of isn't on and so the question there is well even if I set things up for success by switching us to the open Telemetry line instrumentation tooling and then still send it to the same place we now need to run like the collector in multiple places or run like a collector and Refinery just in order to do the same thing that they already do with their built-in tooling so that can be a bit of a bit of a lift because rather than saying install Library it's install a library and have like five things also all right now um going back to um the the first organization where you're you know where they were sending like way too much data after you um after you convince them to like kind of chill do more directed um instrumentation um what was the next sort of hurdle that you experienced there's a notch Turtle there was that the way that company instruction work was very much the over platformed thing this little towards unusual but they had like a developer productivity teams and they didn't really have a platform team what they had Engineers that didn't do work so the engineers didn't do infrastructure stuff they additional code and they would have a bunch of people working on like build tooling and build other stuff like that and so the question was in the way that they do work in order to adopt open Telemetry successfully you would need to essentially build libraries for things or write stuff into the code in a way that Engineers weren't necessarily writing their own instrumentation and that requires working at a level of abstraction that open television is really really difficult so like you can't propagate certain types of information down to challenge fans very easily or really at all um setting up baggage is still very difficult I'm working with contacts can be really tricky if somebody uses an async function then you might drop that and have to reconnect it somehow and if the lifetimes aren't like already set up nicely people can even add their own instrumentation and then it'll get dropped from something because they don't actually understand the full context of where it is they're just random cone and they add something but an open Telemetry you have to understand the call stack not just the functionality and those aren't always the same interesting so how do you um how do you get over that hurdle so at that company I was never able to fully get over that hurdle I just made it better one of the ways that I made it better was essentially following through all of the um fans manually and looking for errors and when I found errors I would like traced it down to the source code and I would do that and um so I ran into like a bunch of very small things of like propagating information wasn't corrupt so it was probably the information of like the helper functions rather than the actual cost sides to activate that and then I had to fix like 500 small things and even when I did that I found that there are a bunch of places where he's looking as contacts weren't being complicated so functions are just being launched or for example calling uh tracing and that was being disconnected from the actual whatever or sometimes things had to end before they started or start before they ended and that got confusion because the language that they're using it's very easy to write code in that logic and it actually is more correct to do it that way but open Telemetry in its design is very much a chicken is called stack a tree shaped um which is really really ergonomic for a language like Java it's not necessarily ergonomic for languages that aren't like that so like react is a really common example because it's a runtime that's asynchronous and it's really difficult to write code in react to the deadline nicely um I suppose a good one closer is a good example of one that doesn't work very well um watch does work but for a very interesting reason and that is because the Russian language cares about lifetimes and so you think about the lifetime of your functions and so you always know what those are and those end up being the natural tracing Point protocol stack based uh tradition Library um but in terms of what we're able to do and how I was fixing it was really mostly in guacamole and doing some weird clever things to pack into the language runtime in order to make things um hit the semantic model differences between open Telemetry and other language things about calling code so were you like a one-woman show doing all of this um so the other person on this was off on a parental leave so for the duration then I was doing this I was actually one person so and that is that is mad impressive um did you want to like pull your hair out some days it was tricky um a lot of it was that one of the benefits of using open Telemetry is that you get like this intuitive sense of what the code is doing at runtime if you play with it enough they had to sit there and kind of like doodle with it and like look things up and I ask questions and get answers and like you have to have that dialogue running and I knew how to do that and no one else at the company was doing that except like one or two people wow and so you had like a very small select power users favorite people and then you had everyone else who may not have even like used open symmetry at all or even news like a vendor in any way whatsoever and so I would get an intuitive sense if one was broken and what was Iran or something and I would say hey like this is an issue and then people wouldn't necessarily believe me oh interesting so how how do you end up convincing them that it is an issue or or could you convince them I guess is the question so when I was able to I was able to take advantage certain people of the things and one of the ways that I did that was essentially my predicting things and then my predictions would turn out to be correct and then I will give a solution to the position and then the solution will work so like one was the database was very very spiky and I mentioned that this was going to cause my some sort of images and one of the reasons that the database was Frankie was because we had like basically uh the disk would slow on a database and so we spent up the disk on the database quite a bit and when that happened like despite this level down these sets were still very spiky in general but despite going high enough to lock things down and um there's small things like that added up over time and people started to believe me a lot more when it came to certain issues but other ones that were more fundamental in the architecture I never actually got around to being able to convince people of that and I actually ended up leaving that company mainly due to that interesting so did you by the time you left did you find there was at least like they're they were getting more out of their observability at that point like because of your efforts like did you at least see some positive results because of that yeah I did so there was a lot better understanding of where they were with the observability people have more of an understanding of how to use it um I had like a couple of things so that it was more useful like they had a lot of it but some things were wrong like um if the air stack was there the air stack died at the wrong spot so it wouldn't actually tell you where the era happened it would tell you where you defined the open Telemetry like the tradition helper which is which is pointless so I fixed that and then all of a sudden the earrings were correct again and people were happy about that then they would actually use it so I hadn't fixed a bunch of things and I had reduced the usage from like two to three hundred events per day or even maybe 50 million events per day to like right and when that happened then people could continue to add open Telemetry and add instrumentation everywhere without running into the physical they were going to blow their budget even more than their own work and that allows people to continue to add more instrumentation so then I guess there it seems like there wasn't an issue per se as far as like getting people to add the instrumentation at that point because they were obviously they had already over instrumented the system previously so now you put them in it was interesting they had over instrumented it but only via Auto instrumentation so there is very little manual stuff done and the manual stuff that was done was often done in a way that made the questions you can ask relatively useless so like one example was there's like at the top of her watched halfway down is when in the life cycle of the call stack is when they would so you get the user ID associated with it because of how the database calls worked but not user ID was never propagated to the top to it was actually impossible to figure out um like how many pages a user was visiting like um like procession like these types of questions whether or not I usually like it's on the same thing over and over because the question we wanted to ask was how effective would database account should be but would it be effective to put radish there somewhere and like probably don't have a 60 second something TTL we we had no idea because we couldn't actually ask that question all the information was there but not actually in a way that made anything possible to look for right because you couldn't look halfway down the um Span in order to get this span of correlated with this one so that tree you can only ask for things on the same level level and down and like filter that way and so they need to fix that but no one necessarily knew how to and no one necessarily knew that they wanted to because they weren't asking that type of question so I bought that up and then people started to get more of a sense of oh here's kind of where we put the information in a way that's visible and to this day I still don't have like a really good way to like explain to people how to think about that other than you do kind of need to display the system I couldn't understand where the data needs to be in order to be useful for asking questions right yeah that makes a lot of sense um so yeah that's so interesting like I find this such an interesting um sort of I don't want to well I guess use case of sorts uh scenario if you will um because there oftentimes we hear we hear the stories of people just struggling with with getting bringing open Telemetry into the organization um and and then starting to instrument and this this feels like it was like one giant anti-pattern of one giant open Telemetry anti-pattern which I think it's a very important thing to be able to discuss because you know like all tools open till Elementary can be grossly misused and then you end up with with scenarios like this where you're instrumenting but you're not getting anything out of it mm-hmm it was really interesting to see how this happened um because it's a lot of what happened is due to how the company works and how it thought about working so it was very anarchic in the sense that Engineers are very very self-directed and they would do things and so the company had a huge cultural issue of intricate 80 percent done with Instagram maybe like 90 percent done and then they would just drop off or someone like outside traffic and had to do something else and no one else would pick it up and no one would like sit there and make sure the things you got like fully finished and so that essentially happened where we had one employee set up the main amount of instrumentation and then one or two people added like some things to it and one or two people added some things to it but no one did like that last 20 percent of actually tuning things down right it is you know they turn everything on they turned it all up they add a bunch of things and the only instrumentation and then no one actually necessarily used it So like um for example the television instrumentation library was something they had to write because they used high school as a language and um you know what that meant was they had each database query they had four different fans it would make a span from the start of the query instead of a transaction an end of a transaction end of a query and so you had and then you have the command of an aquarium itself so every single database call cost at least four to five spans to appear oh wow and there's no way to configure that or turn that down or uh cool unless things or anything like that and what happened was that word to create and then anytime you had like a n plus one pattern just appear instantly in the database you would have given millions of events it's like millions of spans all over the place and then they were like oh well what do we use uh span events instead and most vendors I either charge per ingestion or they charge for like until then actually doesn't shift the cost anywhere it sometimes meets the user interface slightly better but it doesn't shift the cost um which is one of the reasons why people say like have one wide event when you put things in there then like you know have time stamps and don't be afraid to use that um but they were they were using the SDK essentially as the time snap functionality do a Korean event anytime at any time Mark that something happened whether you're a crazy fan anytime something happened a lab formated all the way down to the auto instrumentation huh so that was tricky that was probably like 80 percent of like now we have instrumentation in the database but no one actually said well it turns out literally every other database SDK lets you turn 90 of the auto instrumentation off and for a good reason um same for like instrumenting the um my HTTP server like the web server you highlight the web server and then you have the web framework and both of them had almost identical levels of instrumentation so depending on which endpoint handler was in place you either got one top level or the other top level or both and so you had like a massive amount of certifications of the amount of spans that you might not need and it turns out it's largely because there wasn't really an ergonomic way to say at this to a span if it exists otherwise create your own span and do that like that pattern is really necessary for libraries and it's not actually really relevant in the SDK it's not really mentioned anywhere and it's not really possible for a lot of languages to do right right yeah that is an interesting problem to have so now when you were helping this organization with open Telemetry how well versed were you an open Telemetry at the time so I um was mountable of it and I had I thought about it that I had done some things with that and there have been like a previous company where I had really played with open Telemetry and react and I had set up like some very interesting and overly clever uh typescript helpers the amazing really easy for people and um I had familiarity there but this company is where I had to really dig into the refinery into configuration into operationalizing it and to controlling the cost and understanding it from like that to the perspective of the operator rather than the end user and so that was an interesting change perspective and I ended up reading pretty much the entire RFC for everything most of the SDK code most of like a whole bunch of other things and so I dug really really deeply into it and um to this day it will don't necessarily understand baggage like I understand it but it's kind of not well implemented yeah you were you were mentioning earlier that um it's funny because I was reading up a baggage today um and you were mentioning earlier that baggage is still kind of wonky to to to work with um specifically that um that that what were some of the challenges in working with baggage that you experienced because I I like this would definitely be good feedback for um for the uh Hotel folks the maintainers it comes down to baggage is a really generic tool that ends up being used for like five different things and they mostly come up one you want to stitch together multiple services or when you want to write a library or do something like that or write like um a platform for people so that they can instrument things very easily and not have to worry about certain underlying implementation details you can also use baggage to paper over the API of a lot of things and do what you want to even if you shouldn't necessarily do that to like for example um package or just contact application in general is more or less the only way you can have a directed encyclical graph otherwise you only really have like a linear constant and you have like some ability to form links but not like even that is pretty under economic but you need to know where you're linking to and where or what you're linking from um but baggage will let you like put things in a header so that you have um cost service cost registration the actual distributive part the markets is also the thing that you need if you want to navigate information down to uh public information upper chain and there's also what you need if you want to write some sort of demand processor as a way to work around issues so if you want to have like something added to multiple Spanish down then the only way to do that really as far as I can tell is to write a span processor and use this package to pull that information out so you would add something to the package and then ask the span processor is really thrown the spams it'll reconstrate to that whole tree and figure everything out and then add that in there see more or less rewrite refinery in your code base we'll rewrite the open television collector in your groupies in order to use packets in order to add certain features that aren't in the SDK yet oh interesting did you did you find that uh with with other aspects of open Telemetry as well that were kind of limiting for you when you were working with it when you were digging deep it was I think the main thing that was unlimiting um outside of that aspect was that um it's really hard to make adding instrumentation that's manual ergonomic like um it's just difficult and a lot of that comes down to open Telemetry really wants you to like have written the code right there and you need to kind of know how to do that and it's very hard to wrap the libraries themselves without adding like that extra layer of interaction that makes things hard so unless your language has a very it's massive macro system and you can use that ergonomically it's difficult to do that and so like Ruby gets away with it because it can monkey patch itself and that's how you get that one layer of interaction removed so if you get around that um languages like uh typescript don't and so in typescript like what you really want is something like a decorator you can't get that and um the other issue that I really ran into ergonomically with open Telemetry would have been a based around Asian Guinness world the ancientist one was probably one of the larger beams of my existence and the reason for that is there's multiple different ways you can write and especially as you're going to smoke and there is one way that open television works one with and that would be if the parent function follows a child function is you're going to sleep passes the context into it and then Waits and outlives the challenge function and then end to tone span and so you have like a circuit historic but actually is this only inside the lifetime of the parents span anything other than that use case gets really weird what about uh what about spam links aren't they supposed to kind of alleviate that though this band links do work but you have to know how to use them and so the parent still has to pull the child and then the child has to have the parent ID in order to link to that or I think vice versa I don't know if you can do that but um essentially I couldn't write a function generically so I was unaware that it was being called from the parent and then had to link up to the parent and so that was tricky because a lot of languages you want to write like a library or something and the library can be very agnostic so I don't necessarily want to say this function is called pharmaceutical contest all the time I want to say this function is called basically in this context that's relevant to the application domain and sometimes that's interesting context and in which case it's been called asynchronously but sometimes it's more synchronously and sometimes it's called a different context altogether and I can't express that with open Telemetry very easily if really at all so 19 was what you do before doing sort of instant patterns but you can't do that like very easily it's very unorganomic in a lot of languages got it got it and and speaking of of languages like what what languages were part of that landscape in that organization um so this organization had a typescript and high school as its main languages but I've also done open Telemetry with um I've done it with react I don't know what typescript done with the hospital done it with a little bit of your name um and I thought which one was the least annoying to implement Unleashed annoying to instrument would be probably python because so many other people use Python and python is used in more of a service sound contests and so open Telemetry is often used there um that that was actually more ergonomic python also has like more like decorators and meta programs how many things like that to make it easier to work with yeah um yeah is interesting because it's both a front end and a back-end um and so a lot of things that you can do with it may have to run both in a voucher context and server contest and open television works really well Riverside and very not great on the client side and so dealing with all of those issues can't be really tricky and it may surviving an API that works while I'm bullet is really really hard to like on the client side you want to send as little as data as possible on the service side you want to send as much data as possible to the collectors of The Collector can filter it um and so you have completely need to there you also have the issue of like how do I actually send data to the cluster on the client side which is kind of solved but not really and you end up like writing an API endpoint that supports things to collector so that you can transparently authenticate or not authenticate in a way that light actually works and you can start to try and filter out noise signal I guess someone calling the endpoint or are they just like because of where did they answer something I was reacting the the most annoying one to instrument or was there another language that you've worked with that was even more annoying high school was the most annoying one to instrument how how big is like the the the the hotels support around around High School um the open Telemetry support for high school is actually pretty decent which is really funny because Haskell has a bigger usage Community wise than Master does for open telemetry um yeah and uh so high school is an ergonomic language it's very expressive it's very interesting but the one time of high school is absolutely absurd and makes um open Telemetry extremely difficult so high school is a funny lazy language which means that if you write the code you don't have any control over the lifetime of one the code is executed or actually evaluated or How Deeply it's evaluated and open Telemetry really really wants you to explicitly call things have it starts then and have that happen and turn like point and so in household and laziness makes it interesting because you end up peppering the laziness with the ones of strict functions which are the tracing stuff and to that can mess with your memory usage you can mention your performance you're interested it can match the couple other things and it's very very difficult in language to have something include transparent would you want the tradition to be transparent otherwise the tracing is really tricky and it brings a bunch of other things and so making it transparent actually require the use of unstable Primitives exposed by the internal implementation details of the compiler and the runtime interesting I feel like I learned something new today um I want to go back to another point that you had made earlier on and hopefully I I understood it correctly I think he made a point saying that generally organizations do tend to like create libraries around open Telemetry did I understand you correctly yeah and it's not necessarily the organizations tend to do that it's that that is one of the best ways to multiply efforts when you have like a platform team when you're thinking of things in a platform engineering manner so in general if you have like something people need to care about life testing or instrumentation or runtime performance or some aspect of the code that isn't necessarily functionality getting everyone to care about that equally is really hard it'll live on to have the same level of knowledge it's really hard um in fact it's kind of not even so much as impossible but I think it's I think oh people try too hard to hit and consequently um it ends up being very very useful from a um organization perspective to accelerate your developers by having like libraries built around things or my platforms putting on things so you have like maybe a standard template and then your instrumentations just don't work and your cicds just dealt with and a whole bunch of other things you're done with it and you can use it but these structures are already set up percent of the structure giving people capabilities for handling things taking care of like distribution so that cross service instrumentation to support the Box all those things would be things that I would want to deal with from a platform team perspective of making Telemetry easier to do yeah that makes a lot easier at home really hard so was there um at this previous organization even other org even subsequent organizations is that something that um it's one thing too I I think have have the aspiration to to like abstract that stuff from from folks to you know make sure that they're at the same level when it comes to instrumenting um it's another to like be able to achieve that goal do you feel that in any of the organizations where you worked that that has been actually achieved with with these kinds of libraries I've been able to get things to a point where it was achievable whether or not I actually achieved it uh it's a different question um but so what I mean by that is I was able to figure out ways to um like wrap an abstract away the vast majority of the setup for open Telemetry when I uh typescript or Hassle and I was able to write um rappers around functions in a way that the rappers are transparent so we could have like a bunch of environment variables properly in and a bunch of like sort of stand up for things dealt with in a way that people just needed to set up their application in a certain way and then you got like the very base skeleton of the Tracer and all those things she's just ready to go right and they can like um get the you know without the span sort of function and have like a more limited understandable API where you didn't need to pass in certain types of contents manually they've been able to do that for both and I've even been able to do that in a way that works um isometrically in JavaScript or lifetime script and what what that means is you can have the same code running in server and the browser and it works and that involved a mild amount of crimes it involved a lot of crimes it involves a lot of crimes um you abused how node modules cached a bunch of things and then in chapter return globals and then the Iran certain stable code here and there and then if you import everything in the right order in the right place and then you rely on trade shaking then your bundle on the server can be different than your bundle on the client and you can end up splitting that out in a way that doesn't break the global Singleton pattern of observability of the open Telemetry stuff and also not explained anywhere Switching gears a bit um to uh more managing the infrastructure side of open Telemetry how was that experience for you in contrast to having to I guess to previous rules of of being more I guess who I guess holistically focused or or having to like lean up the clean up the hotel mess how how was how is that in contrast so running open Telemetry is interesting because like you have to open Telemetry collector to run and The Collector like then you have to set it up and if you go outside of essentially any of the very small documentation examples you end up having to read the rfcs for things or you end up having to read the technical like design document and they are not obtuse but the they're understandable by like a select amount of people and you have to really dig in to understand that to like even for the um tail sampling configuration of the open Telemetry collector like an entire document of how to do it is the most difficult thing I've ever seen um it has like different layers of things each one has its own entire language and specification setup and it's wild the honeycomb Refinery is much better in that regard but running Refinery and production is hey janky mouse in a lot of ways and that largely comes down to Refinery is really a tool that they built for themselves and then they made it available to other people and so it here's Refinery if you know how it works great you just run it but otherwise you can run Refinery successfully if you're an organization with high performance cicd the ability to implement things and look at them and you have that ability to like dial things down very rapidly otherwise Refinery is not going to work super well for you and to the organization that I ran refinery in split the difference they had some amount of rapid cicd and some men of that and I was able to look into um laws and stuff like that and get some things down but they use its pattern and Refinery due to how broken the open Telemetry stuff was we ran into essentially every error case and Edge case of it so for example one of the edge cases that we had was many spans were not like you know a minute or two long finished fans were hours long or even days and we had some Spanish door multiple weeks in length and we also had some Spanish that had over three to five million events in them and without ended up being was you would have something that would go you know I started to ask and then so that starts to span and so this would be like an asynchronous job into the asynchronous job would for every single user in the database do a whole bunch of validation stuff and so that would be about like 1000 demands per user times 500 000 users or twenty thousand Spanish per user times forty thousand users or and so like it's it's ridiculous and um or like for every single item in the database check its consistency in one span so that would take like you know 20 hours and uh that would break every possible configuration of Refinery you just can't have this fan that's not broken and also have Refinery store 50 million things in memory so uh I got things improved and uh but ultimately I ended up saying this entire way we do open Telemetry in like this with an asynchronous job is actually now close enough to streaming services that it doesn't work that way and so the wheel dealer streaming services is to do it the way honeycomb does which is you have like um you just send a snapshot of his fan every like minute show any rule of things in the code and that requires you to have written your code in a way that you can roll things up and then send it every minute so you need to completely rewrite how you do most of your task handling to have some sort of like task handling manager that sits there and can collect a bunch of things in every minute do that and start a new span and that is not really possible the way most people write as you're going to stats and fixing that is really tricky because there's not really a wheel if it's now we're not actually just rewriting the code it requires you to really just um start a million different tasks and each task is linked together casually by like span information and then the collector is sort of like does some things in there or maybe your spam processor can roll that up but otherwise you can't actually do that now you should do your tasks in that manner anyway because then it allowed to have a right hand lock and then you can ensure your task consistency is a longer think it's not interested in the middle you should do that anyway because that's how you do it if you understand Distributing systems but you run into this thing in open Telemetry uh it was written by systems-minded people and so a lot of design decisions that they make make sense if you know how to write a standard stability system like of course you use a writer had a lack of question Journal things a question like you want to just spawn an event from like respond one task somewhere for like 20 hours who does that um everyone does that until they know better that's a really good point um we've got about six minutes left um but before we wrap up um I did want um I would like to talk briefly about um uh some of your experience in trying to make the case for open Telemetry to Executives because that's that that can be challenging yeah to open Telemetry um they're making me so there's there's two sides of it there's making the case for any sort of monitoring or observability in general and I was making the case for more open Telemetry specifically yeah potential um and so the second case usually happens when you have some pre-existing stuff and your article and we should not use the existing stuff when we should use this other thing instead and so what you're arguing for there is a migration two migrations a technical migration and the social migration and those are very tricky and so you want those both migrations to happen and so you need to be able to essentially show that the time and effort saved my via this migration will pay for itself in about four months and if you can't show that it will pay for itself in about four months then you probably shouldn't actually do it and you should figure out how to make it pay for itself in four months and then do it otherwise you'll end up with a migration that takes life a year or something and it has no perceivable difference in benefit and then people are not going to be sold on it people need to actually tangibly feel the benefit or the migration is going to feel on the social aspected technically um for a convention organizations that you want to get like any sort of monitoring in general that relies on being able to convince people that the life cycle leads to Encompass more at the life cycle and the easiest way to do that is in my opinion you tie the code lifecycle to the business value delivery life cycle so what can happen in organizations is you have like the developer life cycle which is over here and it's I write code I commit code I merge code and and you have the business lifecycle which is we could um like we do some market research or we get like some seamless research and then we design a product and we get the final features and then that final feature is implemented and then we see what the feedback is and at no point to do those two overlap or cross so that leads to people to my product owners handing features over to developers and developers writing tune and just handing lots of production and instead of playing frisbee you need to merge those and when those get merged then essentially the developers have to care about things all the way to the point where it delivers value to the customer which is absolutely what every executive already wants to have happen the state they have within separated it's what they think is like has to be that way and the second is a it's possible and even desirable to get developers to care about like the uh so outcomes from the customers get them talking to sales people and get them talking to like products people and that will not only improve things for the product improve the internet but it'll actually improve the productivity of the developers and their experience and their ability to do this that usually sounds Executives and you need this the next uh checking after that is once they have you need this if they just look for like observability they're going to get one of like three or four different vendors and probably going to end up an expensive vendor and you need to pick the vendor based on what the business needs and not necessarily what you like the best like for example my current company we have advanced Monument compliance requirements we have it for only one environment I'm not that provides more than one code base and so because of that no one in the company can use anything that isn't fedramp compliant which significantly limits the amount of Advantage we can have to basically one and I don't necessarily want to use that vendor necessarily but I have no plans to migrate off of it if I were to migrate off of it it would be in a very interesting manner what I would do is I would split the environment into two environments and have them be identical one fan of certified one not federam certified and then essentially would have a fenramp program but that would be like a separate sales funnel and anyone who actually needs it can have that because the Phantom amp is valuable in two aspects for the business one is that it gets them certain customers and one is that it gets some certain conversations and for the conversations those people may not be on federal but they make one eventually when it means that I can run the same code base in both locations and use a different vendor and the one that isn't vetramp and if n Ram verified vendor and that one but that whole migration for the current company would be allowed two years of work so are we gonna do that who knows maybe but there's a lot of other questions to ask first and a lot more that we need to do before we can even get to that point yeah speaking as a vendor we've had a lot of conversations about Feb ramp certification and being that not 100 of our employees are in the us we'd have to do exactly what you described and we tried to do that before for HIPAA and it created kind of a weak experience for some customers so yeah it's a tricky problem interesting yeah like the divide into two environments pushed to both environments eventually we figured out that it was hurting our whole development velocity to push to those two different environments and even though we thought it would be very straightforward now uh because you know the environments aren't identical and if you turn one thing off in one environment and keep it on a different environment you're going to get like a completely different experience and so what if you have an outage in one versus the enter yeah there's no way it doesn't hurt development velocity the question is whether it doesn't hurt development velocity more than the benefit from having a different vendor for something else does like if having one vendor would be extremely beneficial and that benefit is more than the harm you get from Harmony developer velocity by splitting your production environments then maybe it makes sense to do that but realistically it probably doesn't because having homogenized too lean that you can build on top of for yourself often end of having a higher reward than having like a quote technically Superior vendor but you have to invest in that yourself exactly yeah and in the case of the HIPAA stuff it didn't because we were able to bring support into HIPAA and there were only like four customers on that sort of private honeycomb instance that had more support for hippo greater support for security and they were large customers but it was like we can't sort of the fact that they were large customers meant that they made requests and that eventually work the two environments to be significantly different okay in my experience one of the most interesting things about HIPAA is that any sort of regulatory environment there's like there's one regulatory environment and then there's like Federal amp and the overlap between people that need any regulatory environment and people that need or really want fun wrap is basically a circle yeah so if you're going to go like oh we're gonna have like a HIPAA environment we're gonna have a fips environment we could have like you know a shock to like it used to be stocked too anyway whatever um but if you if you have my one of those you probably would actually get as much benefit if not more if I'm going straight to fin ramp even though it's like three times as expected to do that at least and the ongoing maintenance burden of that is ridiculous but it gets you on the other customers you need like HIPAA plus fan ramp or fips plus van ramp and that is a really interesting like business thing that's non-obvious any type of regulatory environment completely changes the game for open Telemetry what you can do with it how it works your vendors in general and even like your hiring practices and it's really weird that you can't really have asset but you can't just get HIPAA you really should probably go all the way to a fat ramp just because of who the market is the needs one or both yeah I totally agree with you based on like our experience with that HIPAA server because it turned out there were companies camped on it that just had who went for that offering that just had a desire for like more privacy stricter controls because of how their company culture and their data worked without actually having the need for the Federal Regulation and I think you're right that it makes it easier to sell I think probably we wouldn't end up going in that direction again unless we managed to partner with somebody who was actively like bringing in fedramp customers like some agency that worked with the government or whatever like would have to be but I I wish we had known that at the start and we didn't one thing that would be interesting there would be to have open Telemetry have some sort of like agency that and that agency gets van ramp compliance and then what you can do with that is you can have that agency essentially facilitate the onboarding of open Telemetry vendors or just other observability vendors into the space and you can use that to sort of start Bridging the Gap and giving people more capabilities and sharing that my fan Ram specific architecture concerns in the way that spreads their compliance load amongst multiple companies and if you could do that oh sorry I was very excited by that idea that makes a ton of sense we could maybe make it work through the project and I would say for us as a small vendor that really is a problem that if we are not allowed to have our Engineers who are in other countries touch the system we may only have one engineer working in a particular area and so we have to hire a second person in the U.S which is undoable there are certain ways um and you would need somebody to talk to someone who's experience in Finland like negotiate that would happen like 100 U.S citizenship is in not see her own requirements it's it gets nuanced and it gets tricky oh interesting well I think we have to leave it at that before we got into a funny side um thank you again Hazel for sharing your insights this has been really cool um I I don't think we get to talk to too many people who uh who have had like such Advanced use cases for open Telemetry and and um being able to share that with the community is is really good because I I think a lot of us get you know we we do like those intro tutorials we're like hey that's pretty easy and then you get into like the the guts of it and then that's when you start uh getting into some of those gnarly use cases can be really tricky in life yeah yeah definitely so definitely appreciate that that feedback and and the Viewpoint and you will be back um for hotel in practice I believe on September 14th looking forward to that um do you know what uh what topic you'll be discussing no idea I'm gonna figure it out but it's gonna be a lot of fun so awesome really looking forward to that um thank you again as always super super awesome insights um yeah and uh we will hopefully see everyone um for hotel and practice with hazel on September 14th thank you

